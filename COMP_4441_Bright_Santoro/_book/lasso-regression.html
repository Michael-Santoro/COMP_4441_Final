<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Lasso Regression | COMP 4441 Final Project</title>
  <meta name="description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Lasso Regression | COMP 4441 Final Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Lasso Regression | COMP 4441 Final Project" />
  
  <meta name="twitter:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  

<meta name="author" content="Emma Bright and Michael Santoro" />


<meta name="date" content="2021-06-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="k-nearest-neighbor.html"/>
<link rel="next" href="results.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">COMP 4441 Final Project - Bright, Santoro</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#dataset"><i class="fa fa-check"></i><b>2.1</b> Dataset</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html"><i class="fa fa-check"></i><b>3</b> Data Cleaning and Partitioning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-normalization"><i class="fa fa-check"></i><b>3.1</b> Data Normalization</a></li>
<li class="chapter" data-level="3.2" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-partitioning"><i class="fa fa-check"></i><b>3.2</b> Data Partitioning</a></li>
<li class="chapter" data-level="3.3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#comparing-results"><i class="fa fa-check"></i><b>3.3</b> Comparing Results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#create-random-forest-model"><i class="fa fa-check"></i><b>4.1</b> Create Random Forest Model</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.2</b> Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.3</b> Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#tuning-our-model"><i class="fa fa-check"></i><b>4.4</b> Tuning our Model</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="random-forest.html"><a href="random-forest.html#plotting-the-error-rate"><i class="fa fa-check"></i><b>4.4.1</b> Plotting the Error Rate</a></li>
<li class="chapter" data-level="4.4.2" data-path="random-forest.html"><a href="random-forest.html#tuning-mtry"><i class="fa fa-check"></i><b>4.4.2</b> Tuning mTry</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#recreate-our-random-forest-model"><i class="fa fa-check"></i><b>4.5</b> Recreate our Random Forest Model</a></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.6</b> Rerun Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.7</b> Rerun Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.8" data-path="random-forest.html"><a href="random-forest.html#variable-importance"><i class="fa fa-check"></i><b>4.8</b> Variable Importance</a></li>
<li class="chapter" data-level="4.9" data-path="random-forest.html"><a href="random-forest.html#accuracy"><i class="fa fa-check"></i><b>4.9</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>5</b> K-Nearest Neighbor</a>
<ul>
<li class="chapter" data-level="5.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#data-partitioning-1"><i class="fa fa-check"></i><b>5.1</b> Data Partitioning</a></li>
<li class="chapter" data-level="5.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#determine-the-k-value"><i class="fa fa-check"></i><b>5.2</b> Determine the k-value</a></li>
<li class="chapter" data-level="5.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#knn-prediction"><i class="fa fa-check"></i><b>5.3</b> KNN Prediction</a></li>
<li class="chapter" data-level="5.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#accuracy-1"><i class="fa fa-check"></i><b>5.4</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>6</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lasso-regression.html"><a href="lasso-regression.html#linear-regression"><i class="fa fa-check"></i><b>6.1</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="lasso-regression.html"><a href="lasso-regression.html#what-is-it"><i class="fa fa-check"></i><b>6.1.1</b> What is it?</a></li>
<li class="chapter" data-level="6.1.2" data-path="lasso-regression.html"><a href="lasso-regression.html#assumptions"><i class="fa fa-check"></i><b>6.1.2</b> Assumptions</a></li>
<li class="chapter" data-level="6.1.3" data-path="lasso-regression.html"><a href="lasso-regression.html#single-variable"><i class="fa fa-check"></i><b>6.1.3</b> Single Variable</a></li>
<li class="chapter" data-level="6.1.4" data-path="lasso-regression.html"><a href="lasso-regression.html#multiple-variables"><i class="fa fa-check"></i><b>6.1.4</b> Multiple Variables</a></li>
<li class="chapter" data-level="6.1.5" data-path="lasso-regression.html"><a href="lasso-regression.html#less-variables"><i class="fa fa-check"></i><b>6.1.5</b> Less Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lasso-regression.html"><a href="lasso-regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.3" data-path="lasso-regression.html"><a href="lasso-regression.html#lasso-regression-1"><i class="fa fa-check"></i><b>6.3</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="lasso-regression.html"><a href="lasso-regression.html#features-of-the-glmnet-package"><i class="fa fa-check"></i><b>6.3.1</b> Features of the ‘glmnet’ Package</a></li>
<li class="chapter" data-level="6.3.2" data-path="lasso-regression.html"><a href="lasso-regression.html#elastic-net-regression"><i class="fa fa-check"></i><b>6.3.2</b> Elastic Net Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>7</b> Results</a></li>
<li class="chapter" data-level="8" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>8</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">COMP 4441 Final Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lasso-regression" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Lasso Regression</h1>
<div id="linear-regression" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Linear Regression</h2>
<div id="what-is-it" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> What is it?</h3>
<p>The simplest form of regression is linear regression, which assumes that the predictors have a linear relationship with the target variable. <span class="citation"><a href="#ref-regression_r" role="doc-biblioref">Singh</a> (<a href="#ref-regression_r" role="doc-biblioref">n.d.</a>)</span><br />
</p>
</div>
<div id="assumptions" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Assumptions</h3>
<p>Input is assumed to have a Normal distribution and are not correlated with each other.</p>
<p>We saw in the Descriptive Stats section that visually this factor had a strong correlation with quality.</p>
<p>With these assumptions being true we can model quality with the following equation. <span class="citation"><a href="#ref-elastic_net" role="doc-biblioref">Kane</a> (<a href="#ref-elastic_net" role="doc-biblioref">n.d.</a>)</span></p>
<p><span class="math display">\[ q = a_1x_1 + a_2x_2 + a_3x_3 + \dots + a_2nx_n + b + \epsilon\]</span>
Where <span class="math inline">\(a_1, a_2, \dots, a_n\)</span> are coefficients from the model. <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> are the input variables to the model. <span class="math inline">\(b\)</span> is a factor of the model representing the y-intercept and <span class="math inline">\(q\)</span> is equal to the quality output. Finally, <span class="math inline">\(\epsilon\)</span> is the error.
The method that we use to optimize this model is Ordinary Least Squares (OLS).</p>
</div>
<div id="single-variable" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Single Variable</h3>
<p>In the code-block below we output the summary of just the measurement alcohol into the linear model.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="lasso-regression.html#cb68-1" aria-hidden="true" tabindex="-1"></a>lr<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(quality<span class="sc">~</span>alcohol, <span class="at">data =</span> train)</span>
<span id="cb68-2"><a href="lasso-regression.html#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lr<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = quality ~ alcohol, data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4417 -0.5005 -0.0522  0.4995  3.2074 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.01358    0.02706  185.29   &lt;2e-16 ***
## alcohol      2.23962    0.06800   32.94   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7863 on 4562 degrees of freedom
## Multiple R-squared:  0.1921, Adjusted R-squared:  0.1919 
## F-statistic:  1085 on 1 and 4562 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Focusing on the p-value above we can tell that it is unlikely that by chance we will observe a relationship between alcohol and quality. Which fits our standard threshold of <span class="math inline">\(5\%\)</span>.
We will use the Root Mean Square Error (RMSE) to compare the results of each of the models. <span class="citation"><a href="#ref-RMSE" role="doc-biblioref">Glen</a> (<a href="#ref-RMSE" role="doc-biblioref">n.d.</a>)</span> The Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit. We are looking for a value very close to zero here as the formula is as follows:</p>
<p><span class="math display">\[RMSE = \sqrt{\frac{\sum_{i=1}^{N}(predicted_i - actual_i)^2}{N}}\]</span></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="lasso-regression.html#cb70-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(lr<span class="fl">.1</span>, <span class="at">newdata =</span> test)</span>
<span id="cb70-2"><a href="lasso-regression.html#cb70-2" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.1</span>,test<span class="sc">$</span>quality)</span>
<span id="cb70-3"><a href="lasso-regression.html#cb70-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.1</span></span></code></pre></div>
<pre><code>## [1] 0.77316</code></pre>
<p>Since we will be comparing results to other discrete statistical methods we now calculate an accuracy measure.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="lasso-regression.html#cb72-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.1</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.1</span>)</span>
<span id="cb72-2"><a href="lasso-regression.html#cb72-2" aria-hidden="true" tabindex="-1"></a>acc<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">mean</span>(rp<span class="fl">.1</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
</div>
<div id="multiple-variables" class="section level3" number="6.1.4">
<h3><span class="header-section-number">6.1.4</span> Multiple Variables</h3>
<p>In the code block below we will input all of the variables and examine the output.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="lasso-regression.html#cb73-1" aria-hidden="true" tabindex="-1"></a>lr<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(quality<span class="sc">~</span>., <span class="at">data =</span> train)</span>
<span id="cb73-2"><a href="lasso-regression.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lr<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = quality ~ ., data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6204 -0.4638 -0.0460  0.4627  2.9628 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           5.21981    0.09286  56.213  &lt; 2e-16 ***
## fixed.acidity         0.93217    0.22387   4.164 3.19e-05 ***
## volatile.acidity     -2.06695    0.13890 -14.880  &lt; 2e-16 ***
## citric.acid          -0.29888    0.15704  -1.903   0.0571 .  
## residual.sugar        3.12413    0.39967   7.817 6.68e-15 ***
## chlorides            -0.37223    0.22612  -1.646   0.0998 .  
## free.sulfur.dioxide   1.58600    0.25778   6.153 8.28e-10 ***
## total.sulfur.dioxide -1.11244    0.14508  -7.668 2.12e-14 ***
## density              -3.12231    0.73831  -4.229 2.39e-05 ***
## pH                    0.58725    0.13904   4.224 2.45e-05 ***
## sulphates             1.44233    0.16082   8.968  &lt; 2e-16 ***
## alcohol               1.79685    0.13661  13.153  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7371 on 4552 degrees of freedom
## Multiple R-squared:  0.2915, Adjusted R-squared:  0.2898 
## F-statistic: 170.3 on 11 and 4552 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Reviewing the output we find from the output that the variables that fall under our standard <span class="math inline">\(5\%\)</span> null-hypothesis threshold are: ‘volatile.acidity,’ ‘citric.acid,’ ‘chlorides,’ ‘sulphates,’ and ‘alcohol.’</p>
<p>One of the issues with so many variables is there a risk of including variables that do not affect the outcome.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="lasso-regression.html#cb75-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(lr<span class="fl">.2</span>, <span class="at">newdata =</span> test)</span>
<span id="cb75-2"><a href="lasso-regression.html#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="lasso-regression.html#cb75-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.2</span>,test<span class="sc">$</span>quality)</span>
<span id="cb75-4"><a href="lasso-regression.html#cb75-4" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.2</span></span></code></pre></div>
<pre><code>## [1] 0.7317968</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="lasso-regression.html#cb77-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.2</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.2</span>)</span>
<span id="cb77-2"><a href="lasso-regression.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(rp<span class="fl">.2</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>## [1] 0.5390585</code></pre>
</div>
<div id="less-variables" class="section level3" number="6.1.5">
<h3><span class="header-section-number">6.1.5</span> Less Variables</h3>
<p>In the code block below we will input a subset of the variables and examine the output.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="lasso-regression.html#cb79-1" aria-hidden="true" tabindex="-1"></a>lr<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(quality<span class="sc">~</span> volatile.acidity <span class="sc">+</span> citric.acid <span class="sc">+</span> chlorides <span class="sc">+</span> free.sulfur.dioxide <span class="sc">+</span> sulphates <span class="sc">+</span> alcohol, <span class="at">data =</span> train)</span>
<span id="cb79-2"><a href="lasso-regression.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lr<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = quality ~ volatile.acidity + citric.acid + chlorides + 
##     free.sulfur.dioxide + sulphates + alcohol, data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.7639 -0.4727 -0.0507  0.4813  3.1745 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          5.16190    0.05906  87.404  &lt; 2e-16 ***
## volatile.acidity    -2.06506    0.12577 -16.420  &lt; 2e-16 ***
## citric.acid         -0.26893    0.14025  -1.918   0.0552 .  
## chlorides           -0.51031    0.22066  -2.313   0.0208 *  
## free.sulfur.dioxide  0.81147    0.19723   4.114 3.95e-05 ***
## sulphates            1.33698    0.14654   9.124  &lt; 2e-16 ***
## alcohol              2.19591    0.06904  31.807  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7474 on 4557 degrees of freedom
## Multiple R-squared:  0.2709, Adjusted R-squared:  0.2699 
## F-statistic: 282.2 on 6 and 4557 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="lasso-regression.html#cb81-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(lr<span class="fl">.3</span>, <span class="at">newdata =</span> test)</span>
<span id="cb81-2"><a href="lasso-regression.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="lasso-regression.html#cb81-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.3</span>,test<span class="sc">$</span>quality)</span>
<span id="cb81-4"><a href="lasso-regression.html#cb81-4" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.3</span></span></code></pre></div>
<pre><code>## [1] 0.7376155</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="lasso-regression.html#cb83-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.3</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.3</span>)</span>
<span id="cb83-2"><a href="lasso-regression.html#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(rp<span class="fl">.3</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>## [1] 0.5437144</code></pre>
</div>
</div>
<div id="ridge-regression" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Ridge Regression</h2>
<p>Ridge regression is an extension of linear regression where the loss function is modified to minimize the complexity of the model. This modification is done by adding a penalty parameter that is equivalent to the square of the magnitude of the coefficients. If we re-write the OLS in Matrix for below:
<span class="math display">\[X_tX\beta = X_tY\]</span>
To solve for the <span class="math inline">\(\beta\)</span> terms to obtain the estimation model, we obtain the following.</p>
<p><span class="math display">\[\beta = (X^{&#39;}X)^{-1}X^{&#39;}Y\]</span></p>
<p>Ridge regression modifies the above by adding a small value of <span class="math inline">\(\lambda\)</span>, to the diagonal elements of the correlation matrix.
<span class="math display">\[\beta = (R+\lambda I)^{-1}X^{&#39;}Y\]</span></p>
<p>We need to find an optimal value for the <span class="math inline">\(lambda\)</span> factor. The ‘glmnet’ feature makes this easy for us. It does not accept a data frame though so we need to make a matrix of the the input variables. The other thing that the chunk below is doing is creating a vector of <span class="math inline">\(\lambda\)</span> values that we want to try.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="lasso-regression.html#cb85-1" aria-hidden="true" tabindex="-1"></a>qual <span class="ot">&lt;-</span> train<span class="sc">$</span>quality</span>
<span id="cb85-2"><a href="lasso-regression.html#cb85-2" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span><span class="fu">colnames</span>(train)</span>
<span id="cb85-3"><a href="lasso-regression.html#cb85-3" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> cols[<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(cols)<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb85-4"><a href="lasso-regression.html#cb85-4" aria-hidden="true" tabindex="-1"></a>train.mat <span class="ot">&lt;-</span> train <span class="sc">%&gt;%</span> <span class="fu">select</span>(cols) <span class="sc">%&gt;%</span> <span class="fu">data.matrix</span>()</span></code></pre></div>
<pre><code>## Note: Using an external vector in selections is ambiguous.
## i Use `all_of(cols)` instead of `cols` to silence this message.
## i See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;.
## This message is displayed once per session.</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="lasso-regression.html#cb87-1" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="at">by =</span> <span class="sc">-</span>.<span class="dv">1</span>)</span>
<span id="cb87-2"><a href="lasso-regression.html#cb87-2" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(train.mat, qual, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> lambdas)</span>
<span id="cb87-3"><a href="lasso-regression.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ridge_reg)</span></code></pre></div>
<p><img src="FinalProject-Bright-Santoro_files/figure-html/unnamed-chunk-41-1.png" width="672" />
/ The lowest point in the curve indicates the optimal lambda: the log value of lambda that best minimized the error in cross-validation. This can be pulled out of the glmnet output.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="lasso-regression.html#cb88-1" aria-hidden="true" tabindex="-1"></a>opt_lambda <span class="ot">&lt;-</span> ridge_reg<span class="sc">$</span>lambda.min</span>
<span id="cb88-2"><a href="lasso-regression.html#cb88-2" aria-hidden="true" tabindex="-1"></a>opt_lambda</span></code></pre></div>
<pre><code>## [1] 0.01</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="lasso-regression.html#cb90-1" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="ot">&lt;-</span> ridge_reg<span class="sc">$</span>glmnet.fit</span>
<span id="cb90-2"><a href="lasso-regression.html#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ridge_model)</span></code></pre></div>
<pre><code>##           Length Class     Mode   
## a0         51    -none-    numeric
## beta      561    dgCMatrix S4     
## df         51    -none-    numeric
## dim         2    -none-    numeric
## lambda     51    -none-    numeric
## dev.ratio  51    -none-    numeric
## nulldev     1    -none-    numeric
## npasses     1    -none-    numeric
## jerr        1    -none-    numeric
## offset      1    -none-    logical
## call        5    -none-    call   
## nobs        1    -none-    numeric</code></pre>
<p>Next, we prepare our test data for prediction.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="lasso-regression.html#cb92-1" aria-hidden="true" tabindex="-1"></a>test.mat <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span> <span class="fu">select</span>(cols) <span class="sc">%&gt;%</span> <span class="fu">data.matrix</span>()</span></code></pre></div>
<p>Next, we find the RMSE of the ridge regression.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="lasso-regression.html#cb93-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge_model, <span class="at">s =</span> opt_lambda, <span class="at">newx =</span> test.mat)</span>
<span id="cb93-2"><a href="lasso-regression.html#cb93-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-3"><a href="lasso-regression.html#cb93-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.4</span>,test<span class="sc">$</span>quality)</span>
<span id="cb93-4"><a href="lasso-regression.html#cb93-4" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.4</span></span></code></pre></div>
<pre><code>## [1] 0.7314353</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="lasso-regression.html#cb95-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.4</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.4</span>)</span>
<span id="cb95-2"><a href="lasso-regression.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(rp<span class="fl">.4</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>## [1] 0.5390585</code></pre>
</div>
<div id="lasso-regression-1" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Lasso Regression</h2>
<p>The method for LASSO regression is much similar to the above code wise although it is completing something different. Lasso regression, or the Least Absolute Shrinkage and Selection Operator, is also a modification of linear regression. In lasso, the loss function is modified to minimize the complexity of the model by limiting the sum of the absolute values of the model coefficients. <span class="citation"><a href="#ref-regression_r" role="doc-biblioref">Singh</a> (<a href="#ref-regression_r" role="doc-biblioref">n.d.</a>)</span></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="lasso-regression.html#cb97-1" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="at">by =</span> <span class="sc">-</span>.<span class="dv">1</span>)</span>
<span id="cb97-2"><a href="lasso-regression.html#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="lasso-regression.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting alpha = 1 implements lasso regression</span></span>
<span id="cb97-4"><a href="lasso-regression.html#cb97-4" aria-hidden="true" tabindex="-1"></a>lasso_reg <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(train.mat, qual, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> lambdas)</span>
<span id="cb97-5"><a href="lasso-regression.html#cb97-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso_reg)</span></code></pre></div>
<p><img src="FinalProject-Bright-Santoro_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="lasso-regression.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best </span></span>
<span id="cb98-2"><a href="lasso-regression.html#cb98-2" aria-hidden="true" tabindex="-1"></a>lambda_best <span class="ot">&lt;-</span> lasso_reg<span class="sc">$</span>lambda.min </span>
<span id="cb98-3"><a href="lasso-regression.html#cb98-3" aria-hidden="true" tabindex="-1"></a>lambda_best</span></code></pre></div>
<pre><code>## [1] 0.001</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="lasso-regression.html#cb100-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso_reg, <span class="at">s =</span> lambda_best, <span class="at">newx =</span> test.mat)</span>
<span id="cb100-2"><a href="lasso-regression.html#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="lasso-regression.html#cb100-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.5</span>,test<span class="sc">$</span>quality)</span>
<span id="cb100-4"><a href="lasso-regression.html#cb100-4" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.5</span></span></code></pre></div>
<pre><code>## [1] 0.7315071</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="lasso-regression.html#cb102-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.5</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.5</span>)</span>
<span id="cb102-2"><a href="lasso-regression.html#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(rp<span class="fl">.5</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
<pre><code>## [1] 0.5395758</code></pre>
<div id="features-of-the-glmnet-package" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Features of the ‘glmnet’ Package</h3>
<p><span class="math inline">\(\lambda\)</span> is defined once and <span class="math inline">\(\alpha\)</span> where lasso is scaled by <span class="math inline">\(\alpha\)</span> and ridge penalty is scaled by <span class="math inline">\((1-\alpha\)</span>).</p>
</div>
<div id="elastic-net-regression" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Elastic Net Regression</h3>
<p>Elastic net regression combines the properties of ridge and lasso regression. So, we need a technique to cycle through find the most optimal limiting factors.The first line of code creates a training control object train_cont which specifies how the repeated cross validation will take place. The second line builds the elastic regression model in which a range of possible alpha and lambda values are tested and their optimum value is selected. <span class="citation"><a href="#ref-regression_r" role="doc-biblioref">Singh</a> (<a href="#ref-regression_r" role="doc-biblioref">n.d.</a>)</span></p>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled
## performance measures.</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="lasso-regression.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best tuning parameter</span></span>
<span id="cb105-2"><a href="lasso-regression.html#cb105-2" aria-hidden="true" tabindex="-1"></a>elastic_reg<span class="sc">$</span>bestTune</span></code></pre></div>
<pre><code>##       alpha      lambda
## 6 0.8902916 0.001641559</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="lasso-regression.html#cb107-1" aria-hidden="true" tabindex="-1"></a>elastic_reg <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(train.mat , qual, <span class="at">alpha =</span> elastic_reg<span class="sc">$</span>bestTune[<span class="dv">1</span>,<span class="dv">1</span>], <span class="at">lambda =</span> elastic_reg<span class="sc">$</span>bestTune[<span class="dv">1</span>,<span class="dv">2</span>])</span></code></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="lasso-regression.html#cb108-1" aria-hidden="true" tabindex="-1"></a>p<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">predict</span>(elastic_reg, <span class="at">s =</span> elastic_reg<span class="sc">$</span>bestTune, <span class="at">newx =</span> test.mat)</span>
<span id="cb108-2"><a href="lasso-regression.html#cb108-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-3"><a href="lasso-regression.html#cb108-3" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(p<span class="fl">.6</span>,test<span class="sc">$</span>quality)</span>
<span id="cb108-4"><a href="lasso-regression.html#cb108-4" aria-hidden="true" tabindex="-1"></a>RMSE<span class="fl">.6</span></span></code></pre></div>
<pre><code>## [1] 0.7314186</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="lasso-regression.html#cb110-1" aria-hidden="true" tabindex="-1"></a>rp<span class="fl">.6</span><span class="ot">&lt;-</span><span class="fu">round</span>(p<span class="fl">.6</span>)</span>
<span id="cb110-2"><a href="lasso-regression.html#cb110-2" aria-hidden="true" tabindex="-1"></a>acc<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">mean</span>(rp<span class="fl">.6</span><span class="sc">==</span>test<span class="sc">$</span>quality)</span></code></pre></div>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="lasso-regression.html#cb111-1" aria-hidden="true" tabindex="-1"></a>accuracy[<span class="dv">3</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> acc<span class="fl">.6</span></span></code></pre></div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-RMSE" class="csl-entry">
Glen, Stephanie. n.d. <span>“RMSE: Root Mean Square Error.”</span> <a href="https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error/">https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error/</a>.
</div>
<div id="ref-elastic_net" class="csl-entry">
Kane, Derek. n.d. <span>“Ridge Regression, LASSO, and Elastic Nets.”</span> <a href="https://www.slideshare.net/DerekKane/data-science-part-xii-ridge-regression-lasso-and-elastic-nets, https://www.youtube.com/watch?v=ipb2MhSRGdw">https://www.slideshare.net/DerekKane/data-science-part-xii-ridge-regression-lasso-and-elastic-nets, https://www.youtube.com/watch?v=ipb2MhSRGdw</a>.
</div>
<div id="ref-regression_r" class="csl-entry">
Singh, Deepika. n.d. <span>“Linear, Lasso, and Ridge Regression with r.”</span> <a href="https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r">https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="k-nearest-neighbor.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-LassoRegression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["FinalProject-Bright Santoro.pdf", "FinalProject-Bright Santoro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
