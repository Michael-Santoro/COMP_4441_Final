<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Lasso Regression | COMP 4441 Final Project</title>
  <meta name="description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Lasso Regression | COMP 4441 Final Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Lasso Regression | COMP 4441 Final Project" />
  
  <meta name="twitter:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  

<meta name="author" content="Emma Bright and Michael Santoro" />


<meta name="date" content="2021-05-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="k-nearest-neighbor.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">COMP 4441 Final Project - Bright, Santoro</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#dataset"><i class="fa fa-check"></i><b>2.1</b> Dataset</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html"><i class="fa fa-check"></i><b>3</b> Data Cleaning and Partitioning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-normalization"><i class="fa fa-check"></i><b>3.1</b> Data Normalization</a></li>
<li class="chapter" data-level="3.2" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-partitioning"><i class="fa fa-check"></i><b>3.2</b> Data Partitioning</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#run-random-forest-function"><i class="fa fa-check"></i><b>4.1</b> Run random forest function</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---train-data"><i class="fa fa-check"></i><b>4.2</b> Predicition and COnfusion matrix - train data</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.3</b> Predicition and COnfusion matrix - test data</a></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#error-rate-in-random-forest-model"><i class="fa fa-check"></i><b>4.4</b> Error Rate in Random Forest Model</a></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#tune-mtry"><i class="fa fa-check"></i><b>4.5</b> Tune mtry</a></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#random-forest-1"><i class="fa fa-check"></i><b>4.6</b> Random Forest</a></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---train-data"><i class="fa fa-check"></i><b>4.7</b> Rerun Predicition and Confusion matrix - train data</a></li>
<li class="chapter" data-level="4.8" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.8</b> Rerun Predicition and COnfusion matrix - test data</a></li>
<li class="chapter" data-level="4.9" data-path="random-forest.html"><a href="random-forest.html#number-of-nodes-on-the-trees"><i class="fa fa-check"></i><b>4.9</b> Number of Nodes on the trees</a></li>
<li class="chapter" data-level="4.10" data-path="random-forest.html"><a href="random-forest.html#partial-dependence-plots"><i class="fa fa-check"></i><b>4.10</b> Partial Dependence Plots</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>5</b> K-Nearest Neighbor</a>
<ul>
<li class="chapter" data-level="5.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#load-data"><i class="fa fa-check"></i><b>5.2</b> Load Data</a></li>
<li class="chapter" data-level="5.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clean-and-normalize-the-data."><i class="fa fa-check"></i><b>5.3</b> Clean and Normalize the data.</a></li>
<li class="chapter" data-level="5.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#data-splice"><i class="fa fa-check"></i><b>5.4</b> Data Splice</a></li>
<li class="chapter" data-level="5.5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#model-evaluation"><i class="fa fa-check"></i><b>5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="5.6" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#optimization"><i class="fa fa-check"></i><b>5.6</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>6</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lasso-regression.html"><a href="lasso-regression.html#load-data-1"><i class="fa fa-check"></i><b>6.1</b> Load Data</a></li>
<li class="chapter" data-level="6.2" data-path="lasso-regression.html"><a href="lasso-regression.html#process-reference"><i class="fa fa-check"></i><b>6.2</b> Process Reference</a></li>
<li class="chapter" data-level="6.3" data-path="lasso-regression.html"><a href="lasso-regression.html#data-partitioning-1"><i class="fa fa-check"></i><b>6.3</b> Data Partitioning</a></li>
<li class="chapter" data-level="6.4" data-path="lasso-regression.html"><a href="lasso-regression.html#scaling-the-numeric-features"><i class="fa fa-check"></i><b>6.4</b> Scaling the Numeric Features</a></li>
<li class="chapter" data-level="6.5" data-path="lasso-regression.html"><a href="lasso-regression.html#linear-regression"><i class="fa fa-check"></i><b>6.5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="lasso-regression.html"><a href="lasso-regression.html#what-is-it"><i class="fa fa-check"></i><b>6.5.1</b> What is it?</a></li>
<li class="chapter" data-level="6.5.2" data-path="lasso-regression.html"><a href="lasso-regression.html#single-variable"><i class="fa fa-check"></i><b>6.5.2</b> Single Variable</a></li>
<li class="chapter" data-level="6.5.3" data-path="lasso-regression.html"><a href="lasso-regression.html#multiple-variables"><i class="fa fa-check"></i><b>6.5.3</b> Multiple Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="lasso-regression.html"><a href="lasso-regression.html#regularization"><i class="fa fa-check"></i><b>6.6</b> Regularization</a></li>
<li class="chapter" data-level="6.7" data-path="lasso-regression.html"><a href="lasso-regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.8" data-path="lasso-regression.html"><a href="lasso-regression.html#lasso-regression-1"><i class="fa fa-check"></i><b>6.8</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="lasso-regression.html"><a href="lasso-regression.html#features-of-the-glmnet-package"><i class="fa fa-check"></i><b>6.8.1</b> Features of the ‘glmnet’ Package</a></li>
<li class="chapter" data-level="6.8.2" data-path="lasso-regression.html"><a href="lasso-regression.html#elastic-net-regression"><i class="fa fa-check"></i><b>6.8.2</b> Elastic Net Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">COMP 4441 Final Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lasso-regression" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Lasso Regression</h1>
<div id="load-data-1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Load Data</h2>
<p>We have taken a data-set from Kaggle: <a href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" class="uri">https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009</a>
This data-set inlcudes the measurements from the wine along with its quality rating.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="lasso-regression.html#cb69-1" aria-hidden="true" tabindex="-1"></a>wine<span class="ot">&lt;-</span><span class="fu">read.table</span>(<span class="st">&quot;data/winequality-red.csv&quot;</span>,<span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>,</span>
<span id="cb69-2"><a href="lasso-regression.html#cb69-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">sep=</span><span class="st">&quot;,&quot;</span>,<span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb69-3"><a href="lasso-regression.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(wine)</span></code></pre></div>
<pre><code>## Rows: 1,599
## Columns: 12
## $ fixed.acidity        &lt;dbl&gt; 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7.5, 6.7, 7.5, 5.6, 7.8, 8.9, 8.9, 8.5, 8.1, 7.4, 7.9, 8.9, 7.6, 7.9, ~
## $ volatile.acidity     &lt;dbl&gt; 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600, 0.650, 0.580, 0.500, 0.580, 0.500, 0.615, 0.610, 0.620, 0.620, 0.28~
## $ citric.acid          &lt;dbl&gt; 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00, 0.02, 0.36, 0.08, 0.36, 0.00, 0.29, 0.18, 0.19, 0.56, 0.28, 0.08, 0.~
## $ residual.sugar       &lt;dbl&gt; 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.1, 1.8, 6.1, 1.6, 1.6, 3.8, 3.9, 1.8, 1.7, 4.4, 1.8, 1.8, 2.3, 1.6, 2~
## $ chlorides            &lt;dbl&gt; 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069, 0.065, 0.073, 0.071, 0.097, 0.071, 0.089, 0.114, 0.176, 0.170, 0.09~
## $ free.sulfur.dioxide  &lt;dbl&gt; 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, 16, 9, 52, 51, 35, 16, 6, 17, 29, 23, 10, 9, 21, 11, 4, 10, 14, 8, 17~
## $ total.sulfur.dioxide &lt;dbl&gt; 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 102, 59, 29, 145, 148, 103, 56, 29, 56, 60, 71, 37, 67, 40, 23, 11, 37,~
## $ density              &lt;dbl&gt; 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978, 0.9964, 0.9946, 0.9968, 0.9978, 0.9959, 0.9978, 0.9943, 0.9974, 0.99~
## $ pH                   &lt;dbl&gt; 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39, 3.36, 3.35, 3.28, 3.35, 3.58, 3.26, 3.16, 3.17, 3.30, 3.11, 3.38, 3.~
## $ sulphates            &lt;dbl&gt; 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47, 0.57, 0.80, 0.54, 0.80, 0.52, 1.56, 0.88, 0.93, 0.75, 1.28, 0.50, 1.~
## $ alcohol              &lt;dbl&gt; 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 10.5, 9.2, 10.5, 9.9, 9.1, 9.2, 9.2, 10.5, 9.3, 9.0, 9.2, 9.4, 9.7, 9.~
## $ quality              &lt;int&gt; 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 6, 6, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6, 6, 7, 4,~</code></pre>
</div>
<div id="process-reference" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Process Reference</h2>
<p>The process was followed from this site: <a href="https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r" class="uri">https://www.pluralsight.com/guides/linear-lasso-and-ridge-regression-with-r</a></p>
</div>
<div id="data-partitioning-1" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Data Partitioning</h2>
<p>The below code takes 70% of the data for training and 30% of the code for testing.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="lasso-regression.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>) </span>
<span id="cb71-2"><a href="lasso-regression.html#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="lasso-regression.html#cb71-3" aria-hidden="true" tabindex="-1"></a>index <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(wine), <span class="fl">0.7</span><span class="sc">*</span><span class="fu">nrow</span>(wine)) </span>
<span id="cb71-4"><a href="lasso-regression.html#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="lasso-regression.html#cb71-5" aria-hidden="true" tabindex="-1"></a>train <span class="ot">=</span> wine[index,] <span class="co"># Create the training data </span></span>
<span id="cb71-6"><a href="lasso-regression.html#cb71-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">=</span> wine[<span class="sc">-</span>index,] <span class="co"># Create the test data</span></span>
<span id="cb71-7"><a href="lasso-regression.html#cb71-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-8"><a href="lasso-regression.html#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train)</span></code></pre></div>
<pre><code>## [1] 1119   12</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="lasso-regression.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(test)</span></code></pre></div>
<pre><code>## [1] 480  12</code></pre>
</div>
<div id="scaling-the-numeric-features" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Scaling the Numeric Features</h2>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="lasso-regression.html#cb75-1" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">colnames</span>(wine)</span>
<span id="cb75-2"><a href="lasso-regression.html#cb75-2" aria-hidden="true" tabindex="-1"></a>pre_proc_val <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(train[,cols], <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))</span>
<span id="cb75-3"><a href="lasso-regression.html#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="lasso-regression.html#cb75-4" aria-hidden="true" tabindex="-1"></a>train[,cols] <span class="ot">=</span> <span class="fu">predict</span>(pre_proc_val, train[,cols])</span>
<span id="cb75-5"><a href="lasso-regression.html#cb75-5" aria-hidden="true" tabindex="-1"></a>test[,cols] <span class="ot">=</span> <span class="fu">predict</span>(pre_proc_val, test[,cols])</span>
<span id="cb75-6"><a href="lasso-regression.html#cb75-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-7"><a href="lasso-regression.html#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(train)</span></code></pre></div>
<pre><code>##  fixed.acidity     volatile.acidity    citric.acid       residual.sugar       chlorides        free.sulfur.dioxide total.sulfur.dioxide
##  Min.   :-2.0802   Min.   :-2.26583   Min.   :-1.37809   Min.   :-1.18596   Min.   :-1.58727   Min.   :-1.4109     Min.   :-1.2446     
##  1st Qu.:-0.6928   1st Qu.:-0.76458   1st Qu.:-0.92192   1st Qu.:-0.45565   1st Qu.:-0.36546   1st Qu.:-0.8446     1st Qu.:-0.7471     
##  Median :-0.2304   Median :-0.04176   Median :-0.06029   Median :-0.23655   Median :-0.15480   Median :-0.1840     Median :-0.2496     
##  Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000     Mean   : 0.0000     
##  3rd Qu.: 0.5790   3rd Qu.: 0.62546   3rd Qu.: 0.80135   3rd Qu.: 0.05557   3rd Qu.: 0.05586   3rd Qu.: 0.5710     3rd Qu.: 0.4656     
##  Max.   : 4.1630   Max.   : 5.85201   Max.   : 3.69037   Max.   : 9.47663   Max.   :11.03109   Max.   : 5.2899     Max.   : 7.5552     
##     density               pH             sulphates          alcohol           quality       
##  Min.   :-3.57012   Min.   :-3.68218   Min.   :-1.8820   Min.   :-1.9054   Min.   :-3.3046  
##  1st Qu.:-0.61381   1st Qu.:-0.66652   1st Qu.:-0.6199   1st Qu.:-0.8694   1st Qu.:-0.7831  
##  Median :-0.01507   Median :-0.02489   Median :-0.2183   Median :-0.2101   Median : 0.4777  
##  Mean   : 0.00000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  
##  3rd Qu.: 0.57566   3rd Qu.: 0.55258   3rd Qu.: 0.4127   3rd Qu.: 0.5747   3rd Qu.: 0.4777  
##  Max.   : 3.71106   Max.   : 4.46653   Max.   : 7.6982   Max.   : 3.3687   Max.   : 2.9993</code></pre>
</div>
<div id="linear-regression" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Linear Regression</h2>
<div id="what-is-it" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> What is it?</h3>
<p>The simplest form of regression is linear regression, which assumes that the predictors have a linear relationship with the target variable.
### Assumptions
* Input is assumed to have a Normal distribution and are not correlated with each other.</p>
<p>We saw in the Descriptive Stats section <em>that this was not the case</em></p>
<p>With these assumptions being true we can model quality witht the following equation.</p>
<p><span class="math display">\[ q = a_1x_1 + a_2x_2 + a_3x_3 + \dots + a_2nx_n + b\]</span>
Where <span class="math inline">\(a_1, a_2, \dots, a_n\)</span> are coefficients from the model. <span class="math inline">\(x_1, x_2, \dots, x_n\)</span> are the input variables to the model. <span class="math inline">\(b\)</span> is a factor of the model and <span class="math inline">\(q\)</span> is equal to the quality output.</p>
</div>
<div id="single-variable" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Single Variable</h3>
<p>In the code-block below we output the summary of just the measurement alchol into the linear model.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="lasso-regression.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(quality<span class="sc">~</span>alcohol, <span class="at">data =</span> train))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = quality ~ alcohol, data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5773 -0.4885 -0.2049  0.6305  3.2938 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 5.845e-16  2.587e-02     0.0        1    
## alcohol     5.019e-01  2.588e-02    19.4   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8653 on 1117 degrees of freedom
## Multiple R-squared:  0.252,  Adjusted R-squared:  0.2513 
## F-statistic: 376.2 on 1 and 1117 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Focusing on the p-value above we can tell that it is unlikely that by chance we will observe a relationship between alcohol and quality.</p>
</div>
<div id="multiple-variables" class="section level3" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> Multiple Variables</h3>
<p>In the code block below we will input all of the variables and examine the output.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="lasso-regression.html#cb79-1" aria-hidden="true" tabindex="-1"></a>lr <span class="ot">&lt;-</span> <span class="fu">lm</span>(quality<span class="sc">~</span>fixed.acidity <span class="sc">+</span> volatile.acidity <span class="sc">+</span> citric.acid <span class="sc">+</span> residual.sugar <span class="sc">+</span> chlorides <span class="sc">+</span> free.sulfur.dioxide <span class="sc">+</span> density <span class="sc">+</span> pH <span class="sc">+</span> sulphates <span class="sc">+</span> alcohol, <span class="at">data =</span> train)</span>
<span id="cb79-2"><a href="lasso-regression.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lr)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = quality ~ fixed.acidity + volatile.acidity + citric.acid + 
##     residual.sugar + chlorides + free.sulfur.dioxide + density + 
##     pH + sulphates + alcohol, data = train)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2099 -0.4497 -0.0791  0.5241  2.5651 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -1.898e-15  2.383e-02   0.000  1.00000    
## fixed.acidity        1.248e-01  6.537e-02   1.910  0.05645 .  
## volatile.acidity    -2.657e-01  3.093e-02  -8.589  &lt; 2e-16 ***
## citric.acid         -9.537e-02  4.006e-02  -2.381  0.01744 *  
## residual.sugar       5.473e-02  3.099e-02   1.766  0.07761 .  
## chlorides           -9.002e-02  2.936e-02  -3.066  0.00222 ** 
## free.sulfur.dioxide -4.450e-02  2.517e-02  -1.768  0.07737 .  
## density             -9.071e-02  5.979e-02  -1.517  0.12948    
## pH                  -4.245e-02  4.281e-02  -0.992  0.32162    
## sulphates            1.813e-01  2.888e-02   6.279 4.87e-10 ***
## alcohol              3.934e-01  4.120e-02   9.548  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7972 on 1108 degrees of freedom
## Multiple R-squared:  0.3701, Adjusted R-squared:  0.3644 
## F-statistic:  65.1 on 10 and 1108 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Reviewing the output we find that the inputs: ‘volatile.acidity,’ ‘sulphates,’ and ‘alcohol.’</p>
</div>
</div>
<div id="regularization" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Regularization</h2>
<p>Linear regression algorithm works by selecting coefficients for each independent variable that minimizes a loss function. However, if the coefficients are large, they can lead to over-fitting on the training dataset, and such a model will not generalize well on the unseen test data. To overcome this shortcoming, we’ll do regularization, which penalizes large coefficients. The following sections of the guide will discuss various regularization algorithms.</p>
<p>We will be using the glmnet() package to build the regularized regression models. The glmnet function does not work with dataframes, so we need to create a numeric matrix for the training features and a vector of target values.</p>
<p>The lines of code below perform the task of creating model matrix using the dummyVars function from the caret package. The predict function is then applied to create numeric model matrices for training and test.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="lasso-regression.html#cb81-1" aria-hidden="true" tabindex="-1"></a>dummies <span class="ot">&lt;-</span> <span class="fu">dummyVars</span>(quality<span class="sc">~</span>., <span class="at">data =</span> wine)</span>
<span id="cb81-2"><a href="lasso-regression.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="lasso-regression.html#cb81-3" aria-hidden="true" tabindex="-1"></a>train_dummies <span class="ot">=</span> <span class="fu">predict</span>(dummies, <span class="at">newdata =</span> train)</span>
<span id="cb81-4"><a href="lasso-regression.html#cb81-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-5"><a href="lasso-regression.html#cb81-5" aria-hidden="true" tabindex="-1"></a>test_dummies <span class="ot">=</span> <span class="fu">predict</span>(dummies, <span class="at">newdata =</span> test)</span>
<span id="cb81-6"><a href="lasso-regression.html#cb81-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-7"><a href="lasso-regression.html#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">dim</span>(train_dummies)); <span class="fu">print</span>(<span class="fu">dim</span>(test_dummies))</span></code></pre></div>
<pre><code>## [1] 1119   11</code></pre>
<pre><code>## [1] 480  11</code></pre>
</div>
<div id="ridge-regression" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Ridge Regression</h2>
<p>Ridge regression is an extension of linear regression where the loss function is modified to minimize the complexity of the model. This modification is done by adding a penalty parameter that is equivalent to the square of the magnitude of the coefficients.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="lasso-regression.html#cb84-1" aria-hidden="true" tabindex="-1"></a>eval_results <span class="ot">&lt;-</span> <span class="cf">function</span>(true, predicted, df) {</span>
<span id="cb84-2"><a href="lasso-regression.html#cb84-2" aria-hidden="true" tabindex="-1"></a>  SSE <span class="ot">&lt;-</span> <span class="fu">sum</span>((predicted <span class="sc">-</span> true)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb84-3"><a href="lasso-regression.html#cb84-3" aria-hidden="true" tabindex="-1"></a>  SST <span class="ot">&lt;-</span> <span class="fu">sum</span>((true <span class="sc">-</span> <span class="fu">mean</span>(true))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb84-4"><a href="lasso-regression.html#cb84-4" aria-hidden="true" tabindex="-1"></a>  R_square <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> SSE <span class="sc">/</span> SST</span>
<span id="cb84-5"><a href="lasso-regression.html#cb84-5" aria-hidden="true" tabindex="-1"></a>  RMSE <span class="ot">=</span> <span class="fu">sqrt</span>(SSE<span class="sc">/</span><span class="fu">nrow</span>(df))</span>
<span id="cb84-6"><a href="lasso-regression.html#cb84-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-7"><a href="lasso-regression.html#cb84-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb84-8"><a href="lasso-regression.html#cb84-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Model performance metrics</span></span>
<span id="cb84-9"><a href="lasso-regression.html#cb84-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb84-10"><a href="lasso-regression.html#cb84-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">RMSE =</span> RMSE,</span>
<span id="cb84-11"><a href="lasso-regression.html#cb84-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">Rsquare =</span> R_square</span>
<span id="cb84-12"><a href="lasso-regression.html#cb84-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb84-13"><a href="lasso-regression.html#cb84-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb84-14"><a href="lasso-regression.html#cb84-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="lasso-regression.html#cb85-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">as.matrix</span>(train_dummies)</span>
<span id="cb85-2"><a href="lasso-regression.html#cb85-2" aria-hidden="true" tabindex="-1"></a>y_train <span class="ot">=</span> train<span class="sc">$</span>quality</span>
<span id="cb85-3"><a href="lasso-regression.html#cb85-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-4"><a href="lasso-regression.html#cb85-4" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">=</span> <span class="fu">as.matrix</span>(test_dummies)</span>
<span id="cb85-5"><a href="lasso-regression.html#cb85-5" aria-hidden="true" tabindex="-1"></a>y_test <span class="ot">=</span> test<span class="sc">$</span>unemploy</span>
<span id="cb85-6"><a href="lasso-regression.html#cb85-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-7"><a href="lasso-regression.html#cb85-7" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="at">by =</span> <span class="sc">-</span>.<span class="dv">1</span>)</span>
<span id="cb85-8"><a href="lasso-regression.html#cb85-8" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="ot">=</span> <span class="fu">glmnet</span>(x, y_train, <span class="at">nlambda =</span> <span class="dv">25</span>, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">family =</span> <span class="st">&#39;gaussian&#39;</span>, <span class="at">lambda =</span> lambdas)</span>
<span id="cb85-9"><a href="lasso-regression.html#cb85-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-10"><a href="lasso-regression.html#cb85-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ridge_reg)</span></code></pre></div>
<pre><code>##           Length Class     Mode   
## a0         51    -none-    numeric
## beta      561    dgCMatrix S4     
## df         51    -none-    numeric
## dim         2    -none-    numeric
## lambda     51    -none-    numeric
## dev.ratio  51    -none-    numeric
## nulldev     1    -none-    numeric
## npasses     1    -none-    numeric
## jerr        1    -none-    numeric
## offset      1    -none-    logical
## call        7    -none-    call   
## nobs        1    -none-    numeric</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="lasso-regression.html#cb87-1" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y_train, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> lambdas)</span>
<span id="cb87-2"><a href="lasso-regression.html#cb87-2" aria-hidden="true" tabindex="-1"></a>optimal_lambda <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min</span>
<span id="cb87-3"><a href="lasso-regression.html#cb87-3" aria-hidden="true" tabindex="-1"></a>optimal_lambda</span></code></pre></div>
<pre><code>## [1] 0.05011872</code></pre>
</div>
<div id="lasso-regression-1" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> Lasso Regression</h2>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="lasso-regression.html#cb89-1" aria-hidden="true" tabindex="-1"></a>lambdas <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="at">by =</span> <span class="sc">-</span>.<span class="dv">1</span>)</span>
<span id="cb89-2"><a href="lasso-regression.html#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="lasso-regression.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting alpha = 1 implements lasso regression</span></span>
<span id="cb89-4"><a href="lasso-regression.html#cb89-4" aria-hidden="true" tabindex="-1"></a>lasso_reg <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y_train, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> lambdas, <span class="at">standardize =</span> <span class="cn">TRUE</span>, <span class="at">nfolds =</span> <span class="dv">5</span>)</span>
<span id="cb89-5"><a href="lasso-regression.html#cb89-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-6"><a href="lasso-regression.html#cb89-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Best </span></span>
<span id="cb89-7"><a href="lasso-regression.html#cb89-7" aria-hidden="true" tabindex="-1"></a>lambda_best <span class="ot">&lt;-</span> lasso_reg<span class="sc">$</span>lambda.min </span>
<span id="cb89-8"><a href="lasso-regression.html#cb89-8" aria-hidden="true" tabindex="-1"></a>lambda_best</span></code></pre></div>
<pre><code>## [1] 0.001995262</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="lasso-regression.html#cb91-1" aria-hidden="true" tabindex="-1"></a>lasso_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y_train, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> lambda_best, <span class="at">standardize =</span> <span class="cn">TRUE</span>)</span>
<span id="cb91-2"><a href="lasso-regression.html#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="lasso-regression.html#cb91-3" aria-hidden="true" tabindex="-1"></a>predictions_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso_model, <span class="at">s =</span> lambda_best, <span class="at">newx =</span> x)</span>
<span id="cb91-4"><a href="lasso-regression.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_results</span>(y_train, predictions_train, train)</span></code></pre></div>
<pre><code>##        RMSE   Rsquare
## 1 0.7898025 0.3756541</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="lasso-regression.html#cb93-1" aria-hidden="true" tabindex="-1"></a>predictions_test <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso_model, <span class="at">s =</span> lambda_best, <span class="at">newx =</span> x_test)</span>
<span id="cb93-2"><a href="lasso-regression.html#cb93-2" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_results</span>(y_test, predictions_test, test)</span></code></pre></div>
<pre><code>## Warning in mean.default(true): argument is not numeric or logical: returning NA</code></pre>
<pre><code>##   RMSE Rsquare
## 1    0     NaN</code></pre>
<div id="features-of-the-glmnet-package" class="section level3" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> Features of the ‘glmnet’ Package</h3>
<p><span class="math inline">\(\lambda\)</span> is defined once and <span class="math inline">\(\alpha\)</span> where lasso is scaled by <span class="math inline">\(\alpha\)</span> and ridge penalty is scaled by <span class="math inline">\((1-\alpha\)</span>).</p>
</div>
<div id="elastic-net-regression" class="section level3" number="6.8.2">
<h3><span class="header-section-number">6.8.2</span> Elastic Net Regression</h3>
<p>Elastic net regression combines the properties of ridge and lasso regression</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="lasso-regression.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set training control</span></span>
<span id="cb96-2"><a href="lasso-regression.html#cb96-2" aria-hidden="true" tabindex="-1"></a>train_cont <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,</span>
<span id="cb96-3"><a href="lasso-regression.html#cb96-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb96-4"><a href="lasso-regression.html#cb96-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb96-5"><a href="lasso-regression.html#cb96-5" aria-hidden="true" tabindex="-1"></a>                              <span class="at">search =</span> <span class="st">&quot;random&quot;</span>,</span>
<span id="cb96-6"><a href="lasso-regression.html#cb96-6" aria-hidden="true" tabindex="-1"></a>                              <span class="at">verboseIter =</span> <span class="cn">TRUE</span>)</span>
<span id="cb96-7"><a href="lasso-regression.html#cb96-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-8"><a href="lasso-regression.html#cb96-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb96-9"><a href="lasso-regression.html#cb96-9" aria-hidden="true" tabindex="-1"></a>elastic_reg <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> .,</span>
<span id="cb96-10"><a href="lasso-regression.html#cb96-10" aria-hidden="true" tabindex="-1"></a>                           <span class="at">data =</span> train,</span>
<span id="cb96-11"><a href="lasso-regression.html#cb96-11" aria-hidden="true" tabindex="-1"></a>                           <span class="at">method =</span> <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb96-12"><a href="lasso-regression.html#cb96-12" aria-hidden="true" tabindex="-1"></a>                           <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb96-13"><a href="lasso-regression.html#cb96-13" aria-hidden="true" tabindex="-1"></a>                           <span class="at">tuneLength =</span> <span class="dv">10</span>,</span>
<span id="cb96-14"><a href="lasso-regression.html#cb96-14" aria-hidden="true" tabindex="-1"></a>                           <span class="at">trControl =</span> train_cont)</span></code></pre></div>
<pre><code>## + Fold01.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold01.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold01.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold01.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold01.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold01.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold01.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold01.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold01.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold01.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold01.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold01.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold01.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold01.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold01.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold01.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold01.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold01.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold01.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold01.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold02.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold02.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold02.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold02.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold02.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold02.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold02.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold02.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold02.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold02.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold02.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold02.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold02.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold02.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold02.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold02.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold02.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold02.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold02.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold02.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold03.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold03.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold03.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold03.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold03.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold03.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold03.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold03.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold03.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold03.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold03.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold03.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold03.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold03.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold03.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold03.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold03.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold03.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold03.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold03.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold04.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold04.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold04.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold04.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold04.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold04.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold04.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold04.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold04.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold04.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold04.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold04.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold04.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold04.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold04.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold04.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold04.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold04.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold04.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold04.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold05.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold05.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold05.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold05.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold05.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold05.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold05.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold05.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold05.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold05.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold05.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold05.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold05.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold05.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold05.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold05.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold05.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold05.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold05.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold05.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold06.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold06.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold06.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold06.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold06.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold06.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold06.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold06.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold06.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold06.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold06.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold06.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold06.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold06.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold06.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold06.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold06.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold06.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold06.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold06.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold07.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold07.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold07.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold07.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold07.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold07.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold07.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold07.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold07.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold07.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold07.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold07.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold07.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold07.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold07.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold07.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold07.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold07.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold07.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold07.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold08.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold08.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold08.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold08.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold08.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold08.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold08.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold08.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold08.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold08.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold08.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold08.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold08.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold08.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold08.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold08.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold08.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold08.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold08.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold08.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold09.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold09.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold09.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold09.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold09.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold09.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold09.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold09.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold09.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold09.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold09.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold09.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold09.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold09.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold09.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold09.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold09.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold09.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold09.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold09.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold10.Rep1: alpha=0.4004, lambda=0.002439 
## - Fold10.Rep1: alpha=0.4004, lambda=0.002439 
## + Fold10.Rep1: alpha=0.1857, lambda=1.109010 
## - Fold10.Rep1: alpha=0.1857, lambda=1.109010 
## + Fold10.Rep1: alpha=0.9054, lambda=0.120703 
## - Fold10.Rep1: alpha=0.9054, lambda=0.120703 
## + Fold10.Rep1: alpha=0.5759, lambda=1.247636 
## - Fold10.Rep1: alpha=0.5759, lambda=1.247636 
## + Fold10.Rep1: alpha=0.2560, lambda=0.003753 
## - Fold10.Rep1: alpha=0.2560, lambda=0.003753 
## + Fold10.Rep1: alpha=0.7879, lambda=0.195914 
## - Fold10.Rep1: alpha=0.7879, lambda=0.195914 
## + Fold10.Rep1: alpha=0.4018, lambda=0.086926 
## - Fold10.Rep1: alpha=0.4018, lambda=0.086926 
## + Fold10.Rep1: alpha=0.1517, lambda=1.159105 
## - Fold10.Rep1: alpha=0.1517, lambda=1.159105 
## + Fold10.Rep1: alpha=0.3660, lambda=0.692297 
## - Fold10.Rep1: alpha=0.3660, lambda=0.692297 
## + Fold10.Rep1: alpha=0.2080, lambda=0.003654 
## - Fold10.Rep1: alpha=0.2080, lambda=0.003654 
## + Fold01.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold01.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold01.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold01.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold01.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold01.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold01.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold01.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold01.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold01.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold01.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold01.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold01.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold01.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold01.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold01.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold01.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold01.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold01.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold01.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold02.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold02.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold02.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold02.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold02.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold02.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold02.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold02.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold02.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold02.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold02.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold02.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold02.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold02.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold02.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold02.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold02.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold02.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold02.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold02.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold03.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold03.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold03.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold03.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold03.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold03.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold03.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold03.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold03.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold03.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold03.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold03.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold03.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold03.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold03.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold03.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold03.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold03.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold03.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold03.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold04.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold04.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold04.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold04.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold04.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold04.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold04.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold04.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold04.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold04.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold04.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold04.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold04.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold04.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold04.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold04.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold04.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold04.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold04.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold04.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold05.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold05.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold05.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold05.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold05.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold05.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold05.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold05.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold05.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold05.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold05.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold05.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold05.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold05.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold05.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold05.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold05.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold05.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold05.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold05.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold06.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold06.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold06.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold06.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold06.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold06.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold06.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold06.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold06.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold06.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold06.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold06.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold06.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold06.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold06.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold06.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold06.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold06.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold06.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold06.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold07.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold07.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold07.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold07.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold07.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold07.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold07.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold07.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold07.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold07.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold07.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold07.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold07.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold07.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold07.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold07.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold07.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold07.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold07.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold07.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold08.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold08.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold08.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold08.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold08.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold08.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold08.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold08.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold08.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold08.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold08.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold08.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold08.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold08.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold08.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold08.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold08.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold08.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold08.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold08.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold09.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold09.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold09.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold09.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold09.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold09.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold09.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold09.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold09.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold09.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold09.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold09.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold09.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold09.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold09.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold09.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold09.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold09.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold09.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold09.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold10.Rep2: alpha=0.4004, lambda=0.002439 
## - Fold10.Rep2: alpha=0.4004, lambda=0.002439 
## + Fold10.Rep2: alpha=0.1857, lambda=1.109010 
## - Fold10.Rep2: alpha=0.1857, lambda=1.109010 
## + Fold10.Rep2: alpha=0.9054, lambda=0.120703 
## - Fold10.Rep2: alpha=0.9054, lambda=0.120703 
## + Fold10.Rep2: alpha=0.5759, lambda=1.247636 
## - Fold10.Rep2: alpha=0.5759, lambda=1.247636 
## + Fold10.Rep2: alpha=0.2560, lambda=0.003753 
## - Fold10.Rep2: alpha=0.2560, lambda=0.003753 
## + Fold10.Rep2: alpha=0.7879, lambda=0.195914 
## - Fold10.Rep2: alpha=0.7879, lambda=0.195914 
## + Fold10.Rep2: alpha=0.4018, lambda=0.086926 
## - Fold10.Rep2: alpha=0.4018, lambda=0.086926 
## + Fold10.Rep2: alpha=0.1517, lambda=1.159105 
## - Fold10.Rep2: alpha=0.1517, lambda=1.159105 
## + Fold10.Rep2: alpha=0.3660, lambda=0.692297 
## - Fold10.Rep2: alpha=0.3660, lambda=0.692297 
## + Fold10.Rep2: alpha=0.2080, lambda=0.003654 
## - Fold10.Rep2: alpha=0.2080, lambda=0.003654 
## + Fold01.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold01.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold01.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold01.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold01.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold01.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold01.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold01.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold01.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold01.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold01.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold01.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold01.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold01.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold01.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold01.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold01.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold01.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold01.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold01.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold02.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold02.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold02.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold02.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold02.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold02.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold02.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold02.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold02.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold02.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold02.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold02.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold02.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold02.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold02.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold02.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold02.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold02.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold02.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold02.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold03.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold03.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold03.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold03.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold03.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold03.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold03.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold03.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold03.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold03.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold03.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold03.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold03.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold03.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold03.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold03.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold03.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold03.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold03.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold03.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold04.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold04.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold04.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold04.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold04.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold04.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold04.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold04.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold04.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold04.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold04.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold04.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold04.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold04.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold04.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold04.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold04.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold04.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold04.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold04.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold05.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold05.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold05.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold05.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold05.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold05.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold05.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold05.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold05.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold05.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold05.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold05.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold05.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold05.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold05.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold05.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold05.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold05.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold05.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold05.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold06.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold06.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold06.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold06.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold06.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold06.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold06.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold06.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold06.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold06.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold06.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold06.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold06.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold06.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold06.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold06.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold06.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold06.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold06.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold06.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold07.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold07.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold07.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold07.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold07.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold07.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold07.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold07.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold07.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold07.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold07.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold07.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold07.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold07.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold07.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold07.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold07.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold07.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold07.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold07.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold08.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold08.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold08.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold08.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold08.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold08.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold08.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold08.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold08.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold08.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold08.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold08.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold08.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold08.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold08.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold08.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold08.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold08.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold08.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold08.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold09.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold09.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold09.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold09.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold09.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold09.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold09.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold09.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold09.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold09.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold09.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold09.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold09.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold09.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold09.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold09.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold09.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold09.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold09.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold09.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold10.Rep3: alpha=0.4004, lambda=0.002439 
## - Fold10.Rep3: alpha=0.4004, lambda=0.002439 
## + Fold10.Rep3: alpha=0.1857, lambda=1.109010 
## - Fold10.Rep3: alpha=0.1857, lambda=1.109010 
## + Fold10.Rep3: alpha=0.9054, lambda=0.120703 
## - Fold10.Rep3: alpha=0.9054, lambda=0.120703 
## + Fold10.Rep3: alpha=0.5759, lambda=1.247636 
## - Fold10.Rep3: alpha=0.5759, lambda=1.247636 
## + Fold10.Rep3: alpha=0.2560, lambda=0.003753 
## - Fold10.Rep3: alpha=0.2560, lambda=0.003753 
## + Fold10.Rep3: alpha=0.7879, lambda=0.195914 
## - Fold10.Rep3: alpha=0.7879, lambda=0.195914 
## + Fold10.Rep3: alpha=0.4018, lambda=0.086926 
## - Fold10.Rep3: alpha=0.4018, lambda=0.086926 
## + Fold10.Rep3: alpha=0.1517, lambda=1.159105 
## - Fold10.Rep3: alpha=0.1517, lambda=1.159105 
## + Fold10.Rep3: alpha=0.3660, lambda=0.692297 
## - Fold10.Rep3: alpha=0.3660, lambda=0.692297 
## + Fold10.Rep3: alpha=0.2080, lambda=0.003654 
## - Fold10.Rep3: alpha=0.2080, lambda=0.003654 
## + Fold01.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold01.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold01.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold01.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold01.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold01.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold01.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold01.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold01.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold01.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold01.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold01.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold01.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold01.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold01.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold01.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold01.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold01.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold01.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold01.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold02.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold02.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold02.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold02.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold02.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold02.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold02.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold02.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold02.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold02.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold02.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold02.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold02.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold02.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold02.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold02.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold02.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold02.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold02.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold02.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold03.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold03.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold03.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold03.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold03.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold03.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold03.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold03.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold03.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold03.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold03.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold03.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold03.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold03.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold03.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold03.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold03.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold03.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold03.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold03.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold04.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold04.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold04.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold04.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold04.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold04.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold04.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold04.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold04.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold04.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold04.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold04.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold04.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold04.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold04.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold04.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold04.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold04.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold04.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold04.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold05.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold05.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold05.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold05.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold05.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold05.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold05.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold05.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold05.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold05.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold05.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold05.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold05.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold05.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold05.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold05.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold05.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold05.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold05.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold05.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold06.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold06.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold06.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold06.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold06.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold06.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold06.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold06.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold06.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold06.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold06.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold06.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold06.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold06.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold06.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold06.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold06.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold06.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold06.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold06.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold07.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold07.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold07.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold07.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold07.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold07.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold07.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold07.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold07.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold07.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold07.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold07.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold07.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold07.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold07.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold07.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold07.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold07.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold07.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold07.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold08.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold08.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold08.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold08.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold08.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold08.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold08.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold08.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold08.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold08.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold08.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold08.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold08.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold08.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold08.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold08.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold08.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold08.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold08.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold08.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold09.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold09.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold09.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold09.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold09.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold09.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold09.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold09.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold09.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold09.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold09.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold09.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold09.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold09.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold09.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold09.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold09.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold09.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold09.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold09.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold10.Rep4: alpha=0.4004, lambda=0.002439 
## - Fold10.Rep4: alpha=0.4004, lambda=0.002439 
## + Fold10.Rep4: alpha=0.1857, lambda=1.109010 
## - Fold10.Rep4: alpha=0.1857, lambda=1.109010 
## + Fold10.Rep4: alpha=0.9054, lambda=0.120703 
## - Fold10.Rep4: alpha=0.9054, lambda=0.120703 
## + Fold10.Rep4: alpha=0.5759, lambda=1.247636 
## - Fold10.Rep4: alpha=0.5759, lambda=1.247636 
## + Fold10.Rep4: alpha=0.2560, lambda=0.003753 
## - Fold10.Rep4: alpha=0.2560, lambda=0.003753 
## + Fold10.Rep4: alpha=0.7879, lambda=0.195914 
## - Fold10.Rep4: alpha=0.7879, lambda=0.195914 
## + Fold10.Rep4: alpha=0.4018, lambda=0.086926 
## - Fold10.Rep4: alpha=0.4018, lambda=0.086926 
## + Fold10.Rep4: alpha=0.1517, lambda=1.159105 
## - Fold10.Rep4: alpha=0.1517, lambda=1.159105 
## + Fold10.Rep4: alpha=0.3660, lambda=0.692297 
## - Fold10.Rep4: alpha=0.3660, lambda=0.692297 
## + Fold10.Rep4: alpha=0.2080, lambda=0.003654 
## - Fold10.Rep4: alpha=0.2080, lambda=0.003654 
## + Fold01.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold01.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold01.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold01.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold01.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold01.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold01.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold01.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold01.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold01.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold01.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold01.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold01.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold01.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold01.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold01.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold01.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold01.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold01.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold01.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold02.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold02.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold02.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold02.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold02.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold02.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold02.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold02.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold02.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold02.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold02.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold02.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold02.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold02.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold02.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold02.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold02.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold02.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold02.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold02.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold03.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold03.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold03.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold03.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold03.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold03.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold03.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold03.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold03.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold03.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold03.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold03.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold03.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold03.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold03.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold03.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold03.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold03.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold03.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold03.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold04.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold04.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold04.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold04.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold04.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold04.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold04.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold04.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold04.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold04.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold04.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold04.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold04.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold04.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold04.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold04.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold04.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold04.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold04.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold04.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold05.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold05.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold05.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold05.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold05.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold05.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold05.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold05.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold05.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold05.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold05.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold05.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold05.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold05.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold05.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold05.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold05.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold05.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold05.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold05.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold06.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold06.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold06.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold06.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold06.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold06.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold06.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold06.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold06.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold06.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold06.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold06.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold06.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold06.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold06.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold06.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold06.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold06.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold06.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold06.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold07.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold07.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold07.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold07.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold07.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold07.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold07.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold07.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold07.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold07.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold07.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold07.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold07.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold07.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold07.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold07.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold07.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold07.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold07.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold07.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold08.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold08.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold08.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold08.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold08.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold08.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold08.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold08.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold08.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold08.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold08.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold08.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold08.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold08.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold08.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold08.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold08.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold08.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold08.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold08.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold09.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold09.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold09.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold09.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold09.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold09.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold09.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold09.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold09.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold09.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold09.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold09.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold09.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold09.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold09.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold09.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold09.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold09.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold09.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold09.Rep5: alpha=0.2080, lambda=0.003654 
## + Fold10.Rep5: alpha=0.4004, lambda=0.002439 
## - Fold10.Rep5: alpha=0.4004, lambda=0.002439 
## + Fold10.Rep5: alpha=0.1857, lambda=1.109010 
## - Fold10.Rep5: alpha=0.1857, lambda=1.109010 
## + Fold10.Rep5: alpha=0.9054, lambda=0.120703 
## - Fold10.Rep5: alpha=0.9054, lambda=0.120703 
## + Fold10.Rep5: alpha=0.5759, lambda=1.247636 
## - Fold10.Rep5: alpha=0.5759, lambda=1.247636 
## + Fold10.Rep5: alpha=0.2560, lambda=0.003753 
## - Fold10.Rep5: alpha=0.2560, lambda=0.003753 
## + Fold10.Rep5: alpha=0.7879, lambda=0.195914 
## - Fold10.Rep5: alpha=0.7879, lambda=0.195914 
## + Fold10.Rep5: alpha=0.4018, lambda=0.086926 
## - Fold10.Rep5: alpha=0.4018, lambda=0.086926 
## + Fold10.Rep5: alpha=0.1517, lambda=1.159105 
## - Fold10.Rep5: alpha=0.1517, lambda=1.159105 
## + Fold10.Rep5: alpha=0.3660, lambda=0.692297 
## - Fold10.Rep5: alpha=0.3660, lambda=0.692297 
## + Fold10.Rep5: alpha=0.2080, lambda=0.003654 
## - Fold10.Rep5: alpha=0.2080, lambda=0.003654</code></pre>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : There were missing values in resampled performance measures.</code></pre>
<pre><code>## Aggregating results
## Selecting tuning parameters
## Fitting alpha = 0.208, lambda = 0.00365 on full training set</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="lasso-regression.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best tuning parameter</span></span>
<span id="cb100-2"><a href="lasso-regression.html#cb100-2" aria-hidden="true" tabindex="-1"></a>elastic_reg<span class="sc">$</span>bestTune</span></code></pre></div>
<pre><code>##       alpha      lambda
## 3 0.2079599 0.003654144</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="lasso-regression.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on training set</span></span>
<span id="cb102-2"><a href="lasso-regression.html#cb102-2" aria-hidden="true" tabindex="-1"></a>predictions_train <span class="ot">&lt;-</span> <span class="fu">predict</span>(elastic_reg, x)</span>
<span id="cb102-3"><a href="lasso-regression.html#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_results</span>(y_train, predictions_train, train) </span></code></pre></div>
<pre><code>##        RMSE  Rsquare
## 1 0.7897507 0.375736</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="lasso-regression.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on test set</span></span>
<span id="cb104-2"><a href="lasso-regression.html#cb104-2" aria-hidden="true" tabindex="-1"></a>predictions_test <span class="ot">&lt;-</span> <span class="fu">predict</span>(elastic_reg, x_test)</span>
<span id="cb104-3"><a href="lasso-regression.html#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_results</span>(y_test, predictions_test, test)</span></code></pre></div>
<pre><code>## Warning in mean.default(true): argument is not numeric or logical: returning NA</code></pre>
<pre><code>##   RMSE Rsquare
## 1    0     NaN</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="k-nearest-neighbor.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-LassoRegression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Final Project - Bright Santoro.pdf", "Final Project - Bright Santoro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
