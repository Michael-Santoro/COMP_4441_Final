<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Random Forest | COMP 4441 Final Project</title>
  <meta name="description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Random Forest | COMP 4441 Final Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Random Forest | COMP 4441 Final Project" />
  
  <meta name="twitter:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  

<meta name="author" content="Emma Bright and Michael Santoro" />


<meta name="date" content="2021-06-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-cleaning-and-partitioning.html"/>
<link rel="next" href="k-nearest-neighbor.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">COMP 4441 Final Project - Bright, Santoro</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#dataset"><i class="fa fa-check"></i><b>2.1</b> Dataset</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive Statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#test-for-normality"><i class="fa fa-check"></i><b>2.3</b> Test for Normality</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html"><i class="fa fa-check"></i><b>3</b> Data Cleaning and Partitioning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-normalization"><i class="fa fa-check"></i><b>3.1</b> Data Normalization</a></li>
<li class="chapter" data-level="3.2" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-partitioning"><i class="fa fa-check"></i><b>3.2</b> Data Partitioning</a></li>
<li class="chapter" data-level="3.3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#comparing-results"><i class="fa fa-check"></i><b>3.3</b> Comparing Results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#create-random-forest-model"><i class="fa fa-check"></i><b>4.1</b> Create Random Forest Model</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.2</b> Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.3</b> Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#tuning-our-model"><i class="fa fa-check"></i><b>4.4</b> Tuning our Model</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="random-forest.html"><a href="random-forest.html#plotting-the-error-rate"><i class="fa fa-check"></i><b>4.4.1</b> Plotting the Error Rate</a></li>
<li class="chapter" data-level="4.4.2" data-path="random-forest.html"><a href="random-forest.html#tuning-mtry"><i class="fa fa-check"></i><b>4.4.2</b> Tuning mTry</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#recreate-our-random-forest-model"><i class="fa fa-check"></i><b>4.5</b> Recreate our Random Forest Model</a></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.6</b> Rerun Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.7</b> Rerun Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.8" data-path="random-forest.html"><a href="random-forest.html#variable-importance"><i class="fa fa-check"></i><b>4.8</b> Variable Importance</a></li>
<li class="chapter" data-level="4.9" data-path="random-forest.html"><a href="random-forest.html#accuracy"><i class="fa fa-check"></i><b>4.9</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>5</b> K-Nearest Neighbor</a>
<ul>
<li class="chapter" data-level="5.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#data-partitioning-1"><i class="fa fa-check"></i><b>5.1</b> Data Partitioning</a></li>
<li class="chapter" data-level="5.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#determine-the-k-value"><i class="fa fa-check"></i><b>5.2</b> Determine the k-value</a></li>
<li class="chapter" data-level="5.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#knn-prediction"><i class="fa fa-check"></i><b>5.3</b> KNN Prediction</a></li>
<li class="chapter" data-level="5.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#accuracy-1"><i class="fa fa-check"></i><b>5.4</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>6</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lasso-regression.html"><a href="lasso-regression.html#linear-regression"><i class="fa fa-check"></i><b>6.1</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="lasso-regression.html"><a href="lasso-regression.html#what-is-it"><i class="fa fa-check"></i><b>6.1.1</b> What is it?</a></li>
<li class="chapter" data-level="6.1.2" data-path="lasso-regression.html"><a href="lasso-regression.html#single-variable"><i class="fa fa-check"></i><b>6.1.2</b> Single Variable</a></li>
<li class="chapter" data-level="6.1.3" data-path="lasso-regression.html"><a href="lasso-regression.html#multiple-variables"><i class="fa fa-check"></i><b>6.1.3</b> Multiple Variables</a></li>
<li class="chapter" data-level="6.1.4" data-path="lasso-regression.html"><a href="lasso-regression.html#less-variables"><i class="fa fa-check"></i><b>6.1.4</b> Less Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lasso-regression.html"><a href="lasso-regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.3" data-path="lasso-regression.html"><a href="lasso-regression.html#lasso-regression-1"><i class="fa fa-check"></i><b>6.3</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="lasso-regression.html"><a href="lasso-regression.html#features-of-the-glmnet-package"><i class="fa fa-check"></i><b>6.3.1</b> Features of the ‘glmnet’ Package</a></li>
<li class="chapter" data-level="6.3.2" data-path="lasso-regression.html"><a href="lasso-regression.html#elastic-net-regression"><i class="fa fa-check"></i><b>6.3.2</b> Elastic Net Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>7</b> Results</a></li>
<li class="chapter" data-level="8" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>8</b> References</a></li>
<li class="chapter" data-level="9" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i><b>9</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">COMP 4441 Final Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-forest" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Random Forest</h1>
<p>Decision trees can suffer from from the problem of overfitting. In order to help solve this problem, the Random Forest algorithm was devised. It works by building multiple decision trees and then merging them together to form a prediction.
Random forest can be used to solve both classification and regression problems, however, for our analysis we will be utilizing it solve our classification problem.</p>
<p>Each tree within the Random Forest is grown as follows:</p>
<ol style="list-style-type: decimal">
<li>If the number of cases in the training set is N, sample N cases at random - but with replacement, from the original data. This sample will be the training set for growing the tree.</li>
<li>If there are M input variables, a number m&lt;&lt;M is specified such that at each node, m variables are selected at random out of the M and the best split on these m is used to split the node. The value of m is held constant during the forest growing.</li>
<li>Each tree is grown to the largest extent possible. There is no pruning." (Breiman and Cutler)</li>
</ol>
<div id="create-random-forest-model" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Create Random Forest Model</h2>
<p>We will start by running the randomForest function utilizing the training dataset to train the model.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="random-forest.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">444</span>)</span>
<span id="cb22-2"><a href="random-forest.html#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="random-forest.html#cb22-3" aria-hidden="true" tabindex="-1"></a>rf.train <span class="ot">&lt;-</span> train</span>
<span id="cb22-4"><a href="random-forest.html#cb22-4" aria-hidden="true" tabindex="-1"></a>rf.train<span class="sc">$</span>quality <span class="ot">&lt;-</span><span class="fu">as.factor</span>(rf.train<span class="sc">$</span>quality)</span>
<span id="cb22-5"><a href="random-forest.html#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="random-forest.html#cb22-6" aria-hidden="true" tabindex="-1"></a>rf.test <span class="ot">&lt;-</span> test</span>
<span id="cb22-7"><a href="random-forest.html#cb22-7" aria-hidden="true" tabindex="-1"></a>rf.test<span class="sc">$</span>quality <span class="ot">&lt;-</span><span class="fu">as.factor</span>(rf.test<span class="sc">$</span>quality)</span>
<span id="cb22-8"><a href="random-forest.html#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="random-forest.html#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># quality is a function of all other variables </span></span>
<span id="cb22-10"><a href="random-forest.html#cb22-10" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(quality<span class="sc">~</span>., <span class="at">data=</span>rf.train)</span>
<span id="cb22-11"><a href="random-forest.html#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = quality ~ ., data = rf.train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 32.91%
## Confusion matrix:
##   3  4    5    6   7  8 9 class.error
## 3 0  0   11    8   0  0 0   1.0000000
## 4 0 24   82   43   2  0 0   0.8410596
## 5 0  4 1086  421   7  0 0   0.2845850
## 6 0  1  335 1526 112  1 0   0.2273418
## 7 0  0   21  354 379  6 0   0.5013158
## 8 0  0    3   52  34 47 0   0.6544118
## 9 0  0    0    1   4  0 0   1.0000000</code></pre>
<p>The default number of trees was utilized to run our model (500) and the number of variables tried at each split in the tree was <span class="math inline">\(3\)</span> variables.</p>
<p>The table above shows the confusion matrix for the random forest model created with the training dataset. The out-of-bag (OOB) error is shown to be <span class="math inline">\(32.91\%\)</span>. According to the class.error results, the model was most inaccurate when predicting wines with a quality of <span class="math inline">\(3\)</span> or <span class="math inline">\(9\)</span> with a <span class="math inline">\(100\%\)</span> error rate. It was most accurate when predicting wines of value 6 with only a <span class="math inline">\(22\%\)</span> error rate.</p>
</div>
<div id="predicition-and-confusion-matrix---training-data" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Predicition and Confusion Matrix - Training Data</h2>
<p>The following code runs a prediction of the quality values for the training set using the random forest model created above.</p>
<p>As you can see, all 6 predictions in the predicted values vector are 100% accurate. This makes sense as the random forest model was built using the training data, so it has already “seen” these values.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="random-forest.html#cb24-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, rf.train)</span>
<span id="cb24-2"><a href="random-forest.html#cb24-2" aria-hidden="true" tabindex="-1"></a>p1<span class="ot">&lt;-</span> <span class="fu">droplevels</span>(p1) <span class="co">#drop any unused levels</span></span>
<span id="cb24-3"><a href="random-forest.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(p1) <span class="co"># predicted values</span></span></code></pre></div>
<pre><code>##  1  3  6  7  9 10 
##  5  5  5  5  7  5 
## Levels: 3 4 5 6 7 8 9</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="random-forest.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(rf.train<span class="sc">$</span>quality) <span class="co"># actual values</span></span></code></pre></div>
<pre><code>## [1] 5 5 5 5 7 5
## Levels: 3 4 5 6 7 8 9</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="random-forest.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&#39;caret&#39;, dependencies = TRUE)</span></span>
<span id="cb28-2"><a href="random-forest.html#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="random-forest.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(p1, rf.train<span class="sc">$</span>quality )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    3    4    5    6    7    8    9
##          3   19    0    0    0    0    0    0
##          4    0  151    0    0    0    0    0
##          5    0    0 1518    0    0    0    0
##          6    0    0    0 1975    0    0    0
##          7    0    0    0    0  760    0    0
##          8    0    0    0    0    0  136    0
##          9    0    0    0    0    0    0    5
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9992, 1)
##     No Information Rate : 0.4327     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
## Sensitivity          1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Specificity          1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value       1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value       1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Prevalence           0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Detection Rate       0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Detection Prevalence 0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Balanced Accuracy    1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
##                      Class: 9
## Sensitivity          1.000000
## Specificity          1.000000
## Pos Pred Value       1.000000
## Neg Pred Value       1.000000
## Prevalence           0.001096
## Detection Rate       0.001096
## Detection Prevalence 0.001096
## Balanced Accuracy    1.000000</code></pre>
<p>Using the confusion matrix function from the caret library, we can show the accuracy of our model when predicting the quality values for our training dataset. The accuracy is 100% when utilizing the training dataset with the random forest model trained by the training dataset.</p>
</div>
<div id="predicition-and-confusion-matrix---test-data" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Predicition and Confusion Matrix - Test Data</h2>
<p>The following code runs a prediction of the quality values for the test dataset using the random forest model created with our training dataset from above.</p>
<p>This model was able to predict 4 out of 6 of the first values accurately.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="random-forest.html#cb30-1" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, rf.test)</span>
<span id="cb30-2"><a href="random-forest.html#cb30-2" aria-hidden="true" tabindex="-1"></a>p2<span class="ot">&lt;-</span><span class="fu">droplevels</span>(p2) <span class="co"># drop unused levels</span></span>
<span id="cb30-3"><a href="random-forest.html#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(p2) <span class="co"># predicted values</span></span></code></pre></div>
<pre><code>##  2  4  5  8 11 16 
##  5  5  5  5  5  5 
## Levels: 3 4 5 6 7 8</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="random-forest.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(rf.test<span class="sc">$</span>quality) <span class="co"># actual values</span></span></code></pre></div>
<pre><code>## [1] 5 6 5 7 5 5
## Levels: 3 4 5 6 7 8</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="random-forest.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(p2, rf.test<span class="sc">$</span>quality )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   3   4   5   6   7   8
##          3   0   1   0   0   0   0
##          4   0   8   1   1   0   0
##          5   3  31 448 136   9   0
##          6   7  24 169 680 128  24
##          7   1   1   2  44 178  15
##          8   0   0   0   0   4  18
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6891          
##                  95% CI : (0.6679, 0.7097)
##     No Information Rate : 0.4454          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.512           
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                       Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
## Sensitivity          0.0000000 0.123077   0.7226   0.7898  0.55799 0.315789
## Specificity          0.9994797 0.998929   0.8637   0.6716  0.96097 0.997868
## Pos Pred Value       0.0000000 0.800000   0.7145   0.6589  0.73859 0.818182
## Neg Pred Value       0.9943064 0.970359   0.8683   0.7991  0.91667 0.979592
## Prevalence           0.0056906 0.033626   0.3207   0.4454  0.16503 0.029488
## Detection Rate       0.0000000 0.004139   0.2318   0.3518  0.09208 0.009312
## Detection Prevalence 0.0005173 0.005173   0.3244   0.5339  0.12468 0.011381
## Balanced Accuracy    0.4997399 0.561003   0.7931   0.7307  0.75948 0.656829</code></pre>
<p>Using the confusion matrix function from the caret library, we can show the accuracy of our model in predicting the quality values for our test dataset. The accuracy is roughly 69% when utilizing the test dataset with the random forest model trained by the training dataset.</p>
</div>
<div id="tuning-our-model" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Tuning our Model</h2>
<p>Now, that we have run our initial model, we can focus on fine tuning the random forest parameters in order to create a more accurate predictive model.</p>
<div id="plotting-the-error-rate" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Plotting the Error Rate</h3>
<p>Plotting the error rate to the number of trees can show us where our model has more or less the same level of effectiveness and we can choose a more accurate tree number.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="random-forest.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(rf)</span></code></pre></div>
<p><img src="Final-Project---Bright-Santoro_files/figure-html/unnamed-chunk-19-1.png" width="672" />
The model appears to have a drop off after about 300 trees and then is more or less constant, therefore, we can adjust our tree number in the model to be 300.</p>
</div>
<div id="tuning-mtry" class="section level3" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Tuning mTry</h3>
<p>The mTry value reflects the number of variables tested at each node split. The tuneRF function can be used to determine what our mTry value should be.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="random-forest.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2222</span>)</span>
<span id="cb37-2"><a href="random-forest.html#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="random-forest.html#cb37-3" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">tuneRF</span>(rf.train[,<span class="sc">-</span><span class="dv">12</span>], rf.train[,<span class="dv">12</span>], </span>
<span id="cb37-4"><a href="random-forest.html#cb37-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">stepFactor =</span> <span class="fl">0.5</span>, </span>
<span id="cb37-5"><a href="random-forest.html#cb37-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">plot=</span><span class="cn">TRUE</span>,</span>
<span id="cb37-6"><a href="random-forest.html#cb37-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">ntreeTry =</span> <span class="dv">100</span>,</span>
<span id="cb37-7"><a href="random-forest.html#cb37-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">trace=</span><span class="cn">TRUE</span>,</span>
<span id="cb37-8"><a href="random-forest.html#cb37-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">improve=</span><span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## mtry = 3  OOB error = 33.26% 
## Searching left ...
## mtry = 6     OOB error = 34.36% 
## -0.03293808 0.05 
## Searching right ...
## mtry = 1     OOB error = 33.46% 
## -0.005928854 0.05</code></pre>
<p><img src="Final-Project---Bright-Santoro_files/figure-html/unnamed-chunk-20-1.png" width="672" />
This output indicates that our model hits its lowest error rate when the mTry value is 3, so we can adjust our model to reflect this new value.</p>
</div>
</div>
<div id="recreate-our-random-forest-model" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Recreate our Random Forest Model</h2>
<p>The following code reruns our model utilizing the new tuning parameters found above.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="random-forest.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">444</span>)</span>
<span id="cb39-2"><a href="random-forest.html#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="random-forest.html#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># quality is a function of all other variables </span></span>
<span id="cb39-4"><a href="random-forest.html#cb39-4" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(quality<span class="sc">~</span>., <span class="at">data=</span>rf.train,</span>
<span id="cb39-5"><a href="random-forest.html#cb39-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">ntree=</span><span class="dv">300</span>,</span>
<span id="cb39-6"><a href="random-forest.html#cb39-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">mTry=</span><span class="dv">3</span>, </span>
<span id="cb39-7"><a href="random-forest.html#cb39-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">importance=</span><span class="cn">TRUE</span>,</span>
<span id="cb39-8"><a href="random-forest.html#cb39-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">proximity=</span><span class="cn">TRUE</span>)</span>
<span id="cb39-9"><a href="random-forest.html#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(rf)</span></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = quality ~ ., data = rf.train, ntree = 300,      mTry = 3, importance = TRUE, proximity = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 300
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 32.23%
## Confusion matrix:
##   3  4    5    6   7  8 9 class.error
## 3 0  1   10    8   0  0 0   1.0000000
## 4 0 21   85   45   0  0 0   0.8609272
## 5 0  5 1100  407   6  0 0   0.2753623
## 6 0  1  321 1537 115  1 0   0.2217722
## 7 0  0   22  343 388  7 0   0.4894737
## 8 0  0    4   55  30 47 0   0.6544118
## 9 0  0    0    1   4  0 0   1.0000000</code></pre>
<p>Our original OOB error rate was 32.91% and utilizing our new tuned parameters, our OOB error rate was 32.23%, so it was improved roughly 0.7%.</p>
</div>
<div id="rerun-predicition-and-confusion-matrix---training-data" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Rerun Predicition and Confusion Matrix - Training Data</h2>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="random-forest.html#cb41-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, rf.train)</span>
<span id="cb41-2"><a href="random-forest.html#cb41-2" aria-hidden="true" tabindex="-1"></a>p1<span class="ot">&lt;-</span> <span class="fu">droplevels</span>(p1) <span class="co"># drop any unused levels</span></span>
<span id="cb41-3"><a href="random-forest.html#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(p1) <span class="co"># predicted values</span></span></code></pre></div>
<pre><code>##  1  3  6  7  9 10 
##  5  5  5  5  7  5 
## Levels: 3 4 5 6 7 8 9</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="random-forest.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(rf.train<span class="sc">$</span>quality) <span class="co"># actual values</span></span></code></pre></div>
<pre><code>## [1] 5 5 5 5 7 5
## Levels: 3 4 5 6 7 8 9</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="random-forest.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(p1, rf.train<span class="sc">$</span>quality )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    3    4    5    6    7    8    9
##          3   19    0    0    0    0    0    0
##          4    0  151    0    0    0    0    0
##          5    0    0 1518    0    0    0    0
##          6    0    0    0 1975    0    0    0
##          7    0    0    0    0  760    0    0
##          8    0    0    0    0    0  136    0
##          9    0    0    0    0    0    0    5
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9992, 1)
##     No Information Rate : 0.4327     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
## Sensitivity          1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Specificity          1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value       1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value       1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
## Prevalence           0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Detection Rate       0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Detection Prevalence 0.004163  0.03309   0.3326   0.4327   0.1665   0.0298
## Balanced Accuracy    1.000000  1.00000   1.0000   1.0000   1.0000   1.0000
##                      Class: 9
## Sensitivity          1.000000
## Specificity          1.000000
## Pos Pred Value       1.000000
## Neg Pred Value       1.000000
## Prevalence           0.001096
## Detection Rate       0.001096
## Detection Prevalence 0.001096
## Balanced Accuracy    1.000000</code></pre>
<p>Again, all of our predictions were 100% accurate as the training data had already been “seen” by the model.</p>
</div>
<div id="rerun-predicition-and-confusion-matrix---test-data" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Rerun Predicition and Confusion Matrix - Test Data</h2>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="random-forest.html#cb47-1" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, rf.test)</span>
<span id="cb47-2"><a href="random-forest.html#cb47-2" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(p2) <span class="co"># drop any unuused levels </span></span>
<span id="cb47-3"><a href="random-forest.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(p2) <span class="co"># predicted values</span></span></code></pre></div>
<pre><code>##  2  4  5  8 11 16 
##  5  5  5  5  5  5 
## Levels: 3 4 5 6 7 8</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="random-forest.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(rf.test<span class="sc">$</span>quality) <span class="co"># actual values</span></span></code></pre></div>
<pre><code>## [1] 5 6 5 7 5 5
## Levels: 3 4 5 6 7 8</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="random-forest.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(p2, rf.test<span class="sc">$</span>quality )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   3   4   5   6   7   8
##          3   0   1   0   0   0   0
##          4   0   8   1   2   0   0
##          5   3  32 447 139  10   0
##          6   7  23 170 675 130  25
##          7   1   1   2  45 175  14
##          8   0   0   0   0   4  18
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6844          
##                  95% CI : (0.6632, 0.7051)
##     No Information Rate : 0.4454          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.5047          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                       Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
## Sensitivity          0.0000000 0.123077   0.7210   0.7840  0.54859 0.315789
## Specificity          0.9994797 0.998394   0.8599   0.6688  0.96097 0.997868
## Pos Pred Value       0.0000000 0.727273   0.7084   0.6553  0.73529 0.818182
## Neg Pred Value       0.9943064 0.970343   0.8671   0.7940  0.91504 0.979592
## Prevalence           0.0056906 0.033626   0.3207   0.4454  0.16503 0.029488
## Detection Rate       0.0000000 0.004139   0.2312   0.3492  0.09053 0.009312
## Detection Prevalence 0.0005173 0.005691   0.3264   0.5329  0.12312 0.011381
## Balanced Accuracy    0.4997399 0.560735   0.7904   0.7264  0.75478 0.656829</code></pre>
<p>The accuracy is roughly <span class="math inline">\(68.24\%\)</span> when utilizing the test dataset with the new random forest model. This is a <span class="math inline">\(0.7\%\)</span> improvement from the previous results of <span class="math inline">\(68.91\%\)</span>.</p>
</div>
<div id="variable-importance" class="section level2" number="4.8">
<h2><span class="header-section-number">4.8</span> Variable Importance</h2>
<p>We are able to see the variables that had the highest level of importance in our model by running the varImpPlot function.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="random-forest.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf, </span>
<span id="cb53-2"><a href="random-forest.html#cb53-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">main=</span><span class="st">&quot;Variable Importance&quot;</span>)</span></code></pre></div>
<p><img src="Final-Project---Bright-Santoro_files/figure-html/unnamed-chunk-26-1.png" width="672" />
This tells us that alcohol has the greatest importance in our model. Removing this variable would result in a 75% mean decrease in accuracy.</p>
</div>
<div id="accuracy" class="section level2" number="4.9">
<h2><span class="header-section-number">4.9</span> Accuracy</h2>
<p>In the code below we are adding the percentage accuracy to the accuracy dataframe for later model comparison.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="random-forest.html#cb54-1" aria-hidden="true" tabindex="-1"></a>accuracy[<span class="dv">2</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(p2, rf.test<span class="sc">$</span>quality )[[<span class="st">&quot;overall&quot;</span>]][[<span class="st">&quot;Accuracy&quot;</span>]]</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-cleaning-and-partitioning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="k-nearest-neighbor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-RandomForest.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Final Project - Bright Santoro.pdf", "Final Project - Bright Santoro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
