<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project</title>
  <meta name="description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project" />
  
  <meta name="twitter:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  

<meta name="author" content="Emma Bright and Michael Santoro" />


<meta name="date" content="2021-05-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-forest.html"/>
<link rel="next" href="lasso-regression.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">COMP 4441 Final Project - Bright, Santoro</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#dataset"><i class="fa fa-check"></i><b>2.1</b> Dataset</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html"><i class="fa fa-check"></i><b>3</b> Data Cleaning and Partitioning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-normalization"><i class="fa fa-check"></i><b>3.1</b> Data Normalization</a></li>
<li class="chapter" data-level="3.2" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-partitioning"><i class="fa fa-check"></i><b>3.2</b> Data Partitioning</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#run-random-forest-function"><i class="fa fa-check"></i><b>4.1</b> Run random forest function</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---train-data"><i class="fa fa-check"></i><b>4.2</b> Predicition and COnfusion matrix - train data</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.3</b> Predicition and COnfusion matrix - test data</a></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#error-rate-in-random-forest-model"><i class="fa fa-check"></i><b>4.4</b> Error Rate in Random Forest Model</a></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#tune-mtry"><i class="fa fa-check"></i><b>4.5</b> Tune mtry</a></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#random-forest-1"><i class="fa fa-check"></i><b>4.6</b> Random Forest</a></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---train-data"><i class="fa fa-check"></i><b>4.7</b> Rerun Predicition and Confusion matrix - train data</a></li>
<li class="chapter" data-level="4.8" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.8</b> Rerun Predicition and COnfusion matrix - test data</a></li>
<li class="chapter" data-level="4.9" data-path="random-forest.html"><a href="random-forest.html#number-of-nodes-on-the-trees"><i class="fa fa-check"></i><b>4.9</b> Number of Nodes on the trees</a></li>
<li class="chapter" data-level="4.10" data-path="random-forest.html"><a href="random-forest.html#partial-dependence-plots"><i class="fa fa-check"></i><b>4.10</b> Partial Dependence Plots</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>5</b> K-Nearest Neighbor</a>
<ul>
<li class="chapter" data-level="5.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#introduction-1"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#load-data"><i class="fa fa-check"></i><b>5.2</b> Load Data</a></li>
<li class="chapter" data-level="5.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clean-and-normalize-the-data."><i class="fa fa-check"></i><b>5.3</b> Clean and Normalize the data.</a></li>
<li class="chapter" data-level="5.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#data-splice"><i class="fa fa-check"></i><b>5.4</b> Data Splice</a></li>
<li class="chapter" data-level="5.5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#model-evaluation"><i class="fa fa-check"></i><b>5.5</b> Model Evaluation</a></li>
<li class="chapter" data-level="5.6" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#optimization"><i class="fa fa-check"></i><b>5.6</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>6</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lasso-regression.html"><a href="lasso-regression.html#load-data-1"><i class="fa fa-check"></i><b>6.1</b> Load Data</a></li>
<li class="chapter" data-level="6.2" data-path="lasso-regression.html"><a href="lasso-regression.html#process-reference"><i class="fa fa-check"></i><b>6.2</b> Process Reference</a></li>
<li class="chapter" data-level="6.3" data-path="lasso-regression.html"><a href="lasso-regression.html#data-partitioning-1"><i class="fa fa-check"></i><b>6.3</b> Data Partitioning</a></li>
<li class="chapter" data-level="6.4" data-path="lasso-regression.html"><a href="lasso-regression.html#scaling-the-numeric-features"><i class="fa fa-check"></i><b>6.4</b> Scaling the Numeric Features</a></li>
<li class="chapter" data-level="6.5" data-path="lasso-regression.html"><a href="lasso-regression.html#linear-regression"><i class="fa fa-check"></i><b>6.5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="lasso-regression.html"><a href="lasso-regression.html#what-is-it"><i class="fa fa-check"></i><b>6.5.1</b> What is it?</a></li>
<li class="chapter" data-level="6.5.2" data-path="lasso-regression.html"><a href="lasso-regression.html#single-variable"><i class="fa fa-check"></i><b>6.5.2</b> Single Variable</a></li>
<li class="chapter" data-level="6.5.3" data-path="lasso-regression.html"><a href="lasso-regression.html#multiple-variables"><i class="fa fa-check"></i><b>6.5.3</b> Multiple Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="lasso-regression.html"><a href="lasso-regression.html#regularization"><i class="fa fa-check"></i><b>6.6</b> Regularization</a></li>
<li class="chapter" data-level="6.7" data-path="lasso-regression.html"><a href="lasso-regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.8" data-path="lasso-regression.html"><a href="lasso-regression.html#lasso-regression-1"><i class="fa fa-check"></i><b>6.8</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="lasso-regression.html"><a href="lasso-regression.html#features-of-the-glmnet-package"><i class="fa fa-check"></i><b>6.8.1</b> Features of the ‘glmnet’ Package</a></li>
<li class="chapter" data-level="6.8.2" data-path="lasso-regression.html"><a href="lasso-regression.html#elastic-net-regression"><i class="fa fa-check"></i><b>6.8.2</b> Elastic Net Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">COMP 4441 Final Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="k-nearest-neighbor" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> K-Nearest Neighbor</h1>
<div id="introduction-1" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<p>Just planning to use this file to walk through some tutorials of k-means clustering I found.</p>
</div>
<div id="load-data" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Load Data</h2>
<p>We have taken a data-set from Kaggle: <a href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" class="uri">https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009</a>
This data-set inlcudes the measurements from the wine along with its quality rating.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="k-nearest-neighbor.html#cb54-1" aria-hidden="true" tabindex="-1"></a>wine<span class="ot">&lt;-</span><span class="fu">read.table</span>(<span class="st">&quot;data/winequality-red.csv&quot;</span>,<span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>,</span>
<span id="cb54-2"><a href="k-nearest-neighbor.html#cb54-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">sep=</span><span class="st">&quot;,&quot;</span>,<span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb54-3"><a href="k-nearest-neighbor.html#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(wine)</span></code></pre></div>
<pre><code>##   fixed.acidity volatile.acidity citric.acid residual.sugar chlorides free.sulfur.dioxide total.sulfur.dioxide density   pH sulphates alcohol
## 1           7.4             0.70        0.00            1.9     0.076                  11                   34  0.9978 3.51      0.56     9.4
## 2           7.8             0.88        0.00            2.6     0.098                  25                   67  0.9968 3.20      0.68     9.8
## 3           7.8             0.76        0.04            2.3     0.092                  15                   54  0.9970 3.26      0.65     9.8
## 4          11.2             0.28        0.56            1.9     0.075                  17                   60  0.9980 3.16      0.58     9.8
## 5           7.4             0.70        0.00            1.9     0.076                  11                   34  0.9978 3.51      0.56     9.4
## 6           7.4             0.66        0.00            1.8     0.075                  13                   40  0.9978 3.51      0.56     9.4
##   quality
## 1       5
## 2       5
## 3       5
## 4       6
## 5       5
## 6       5</code></pre>
</div>
<div id="clean-and-normalize-the-data." class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Clean and Normalize the data.</h2>
<p>Our dataset already contains only predictive values and output, so we do not need to remove any descriptive columns. We must normalize the values within the dataset to avoid any bias and remove the output variable (quality) since it’s the prediction.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="k-nearest-neighbor.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Normalization</span></span>
<span id="cb56-2"><a href="k-nearest-neighbor.html#cb56-2" aria-hidden="true" tabindex="-1"></a>normalize <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb56-3"><a href="k-nearest-neighbor.html#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span> ((x <span class="sc">-</span> <span class="fu">min</span>(x)) <span class="sc">/</span> (<span class="fu">max</span>(x) <span class="sc">-</span> <span class="fu">min</span>(x))) }</span>
<span id="cb56-4"><a href="k-nearest-neighbor.html#cb56-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-5"><a href="k-nearest-neighbor.html#cb56-5" aria-hidden="true" tabindex="-1"></a>wine.normal <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">lapply</span>(wine[,<span class="dv">1</span><span class="sc">:</span><span class="dv">11</span>], normalize))</span>
<span id="cb56-6"><a href="k-nearest-neighbor.html#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="k-nearest-neighbor.html#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(wine.normal)</span></code></pre></div>
<pre><code>##   fixed.acidity volatile.acidity citric.acid residual.sugar chlorides free.sulfur.dioxide total.sulfur.dioxide   density        pH sulphates
## 1     0.2477876        0.3972603        0.00     0.06849315 0.1068447           0.1408451           0.09893993 0.5675477 0.6062992 0.1377246
## 2     0.2831858        0.5205479        0.00     0.11643836 0.1435726           0.3380282           0.21554770 0.4941263 0.3622047 0.2095808
## 3     0.2831858        0.4383562        0.04     0.09589041 0.1335559           0.1971831           0.16961131 0.5088106 0.4094488 0.1916168
## 4     0.5840708        0.1095890        0.56     0.06849315 0.1051753           0.2253521           0.19081272 0.5822320 0.3307087 0.1497006
## 5     0.2477876        0.3972603        0.00     0.06849315 0.1068447           0.1408451           0.09893993 0.5675477 0.6062992 0.1377246
## 6     0.2477876        0.3698630        0.00     0.06164384 0.1051753           0.1690141           0.12014134 0.5675477 0.6062992 0.1377246
##     alcohol
## 1 0.1538462
## 2 0.2153846
## 3 0.2153846
## 4 0.2153846
## 5 0.1538462
## 6 0.1538462</code></pre>
</div>
<div id="data-splice" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Data Splice</h2>
<p>Since our data-set our research question involves prediction will will randomly select a portion of data to use for overall effectiveness measurement. We plan to save about <span class="math inline">\(5\%\)</span> of the data for testing which ends up being <span class="math inline">\(80\)</span> values.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="k-nearest-neighbor.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb58-2"><a href="k-nearest-neighbor.html#cb58-2" aria-hidden="true" tabindex="-1"></a>dat.d <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(wine.normal),<span class="at">size=</span><span class="fu">nrow</span>(wine.normal)<span class="sc">*</span><span class="fl">0.8</span>,<span class="at">replace =</span> <span class="cn">FALSE</span>) <span class="co">#random selection of 90% data.</span></span>
<span id="cb58-3"><a href="k-nearest-neighbor.html#cb58-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb58-4"><a href="k-nearest-neighbor.html#cb58-4" aria-hidden="true" tabindex="-1"></a>train.wine <span class="ot">&lt;-</span> wine.normal[dat.d,] <span class="co"># 90% training data</span></span>
<span id="cb58-5"><a href="k-nearest-neighbor.html#cb58-5" aria-hidden="true" tabindex="-1"></a>test.wine <span class="ot">&lt;-</span> wine.normal[<span class="sc">-</span>dat.d,] <span class="co"># remaining 10% test data</span></span>
<span id="cb58-6"><a href="k-nearest-neighbor.html#cb58-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-7"><a href="k-nearest-neighbor.html#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="k-nearest-neighbor.html#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating seperate dataframe for &#39;Quality&#39; feature which is our target.</span></span>
<span id="cb58-9"><a href="k-nearest-neighbor.html#cb58-9" aria-hidden="true" tabindex="-1"></a>train.quality_label <span class="ot">&lt;-</span> wine[dat.d,<span class="dv">12</span>]</span>
<span id="cb58-10"><a href="k-nearest-neighbor.html#cb58-10" aria-hidden="true" tabindex="-1"></a>test.quality_label <span class="ot">&lt;-</span>wine[<span class="sc">-</span>dat.d,<span class="dv">12</span>]</span></code></pre></div>
<p>Next, we’re going to calculate the number of observations in the training data set. The reason we’re doing this is that we want to initialize the value of ‘K’ in the KNN model. One of the ways to find the optimal K value is to calculate the square root of the total number of observations in the data set. This square root will give you the ‘K’ value.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="k-nearest-neighbor.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">NROW</span>(train.quality_label) </span></code></pre></div>
<pre><code>## [1] 1279</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="k-nearest-neighbor.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">NROW</span>(train.quality_label) )</span></code></pre></div>
<pre><code>## [1] 35.76311</code></pre>
<p>The square root of 1493 is around 35.7 we’ll create a model with a ‘K’ value as 36.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="k-nearest-neighbor.html#cb63-1" aria-hidden="true" tabindex="-1"></a>knn<span class="fl">.36</span> <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train=</span>train.wine, <span class="at">test=</span>test.wine, <span class="at">cl=</span>train.quality_label, <span class="at">k=</span><span class="dv">36</span>)</span></code></pre></div>
</div>
<div id="model-evaluation" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Model Evaluation</h2>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="k-nearest-neighbor.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculate the proportion of correct classification for k =37</span></span>
<span id="cb64-2"><a href="k-nearest-neighbor.html#cb64-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-3"><a href="k-nearest-neighbor.html#cb64-3" aria-hidden="true" tabindex="-1"></a>ACC<span class="fl">.36</span> <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fu">sum</span>(test.quality_label <span class="sc">==</span> knn<span class="fl">.36</span>)<span class="sc">/</span><span class="fu">NROW</span>(test.quality_label)</span>
<span id="cb64-4"><a href="k-nearest-neighbor.html#cb64-4" aria-hidden="true" tabindex="-1"></a>ACC<span class="fl">.36</span></span></code></pre></div>
<pre><code>## [1] 58.4375</code></pre>
<p>As shown above, the accuracy for K = 36 is 58.435</p>
</div>
<div id="optimization" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Optimization</h2>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="k-nearest-neighbor.html#cb66-1" aria-hidden="true" tabindex="-1"></a>i<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb66-2"><a href="k-nearest-neighbor.html#cb66-2" aria-hidden="true" tabindex="-1"></a>k.optm<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb66-3"><a href="k-nearest-neighbor.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">37</span>){</span>
<span id="cb66-4"><a href="k-nearest-neighbor.html#cb66-4" aria-hidden="true" tabindex="-1"></a>  knn.mod <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train=</span>train.wine, <span class="at">test=</span>test.wine, <span class="at">cl=</span>train.quality_label, <span class="at">k=</span>i)</span>
<span id="cb66-5"><a href="k-nearest-neighbor.html#cb66-5" aria-hidden="true" tabindex="-1"></a>  k.optm[i] <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fu">sum</span>(test.quality_label <span class="sc">==</span> knn.mod)<span class="sc">/</span><span class="fu">NROW</span>(test.quality_label)</span>
<span id="cb66-6"><a href="k-nearest-neighbor.html#cb66-6" aria-hidden="true" tabindex="-1"></a>  k<span class="ot">=</span>i</span>
<span id="cb66-7"><a href="k-nearest-neighbor.html#cb66-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(k,<span class="st">&#39;=&#39;</span>,k.optm[i],<span class="st">&#39;&#39;</span>)</span>
<span id="cb66-8"><a href="k-nearest-neighbor.html#cb66-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## 1 = 61.875 2 = 56.875 3 = 56.875 4 = 61.25 5 = 59.0625 6 = 58.125 7 = 55.625 8 = 57.1875 9 = 57.5 10 = 56.875 11 = 59.0625 12 = 59.375 13 = 58.75 14 = 59.375 15 = 60 16 = 60.3125 17 = 61.25 18 = 60.9375 19 = 60 20 = 59.0625 21 = 59.375 22 = 59.375 23 = 59.6875 24 = 59.0625 25 = 58.125 26 = 58.125 27 = 59.0625 28 = 59.0625 29 = 58.4375 30 = 58.4375 31 = 58.75 32 = 59.375 33 = 60 34 = 60.3125 35 = 59.6875 36 = 59.0625 37 = 59.375</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="k-nearest-neighbor.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Accuracy plot</span></span>
<span id="cb68-2"><a href="k-nearest-neighbor.html#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k.optm, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;K- Value&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Accuracy level&quot;</span>)</span></code></pre></div>
<p><img src="Final-Project---Bright-Santoro_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-forest.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lasso-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-KMeans_Testing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Final Project - Bright Santoro.pdf", "Final Project - Bright Santoro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
