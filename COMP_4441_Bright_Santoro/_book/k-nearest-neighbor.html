<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project</title>
  <meta name="description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 K-Nearest Neighbor | COMP 4441 Final Project" />
  
  <meta name="twitter:description" content="This bookdown contains the write up and analysis of the COMP 4441 Final Project for Michael Santoro and Emma Bright." />
  

<meta name="author" content="Emma Bright and Michael Santoro" />


<meta name="date" content="2021-06-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-forest.html"/>
<link rel="next" href="lasso-regression.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">COMP 4441 Final Project - Bright, Santoro</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html"><i class="fa fa-check"></i><b>2</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#dataset"><i class="fa fa-check"></i><b>2.1</b> Dataset</a></li>
<li class="chapter" data-level="2.2" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="descriptive-statistics.html"><a href="descriptive-statistics.html#descriptive-statistics-1"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html"><i class="fa fa-check"></i><b>3</b> Data Cleaning and Partitioning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-normalization"><i class="fa fa-check"></i><b>3.1</b> Data Normalization</a></li>
<li class="chapter" data-level="3.2" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#data-partitioning"><i class="fa fa-check"></i><b>3.2</b> Data Partitioning</a></li>
<li class="chapter" data-level="3.3" data-path="data-cleaning-and-partitioning.html"><a href="data-cleaning-and-partitioning.html#comparing-results"><i class="fa fa-check"></i><b>3.3</b> Comparing Results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4</b> Random Forest</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html#create-random-forest-model"><i class="fa fa-check"></i><b>4.1</b> Create Random Forest Model</a></li>
<li class="chapter" data-level="4.2" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.2</b> Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.3" data-path="random-forest.html"><a href="random-forest.html#predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.3</b> Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.4" data-path="random-forest.html"><a href="random-forest.html#tuning-our-model"><i class="fa fa-check"></i><b>4.4</b> Tuning our Model</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="random-forest.html"><a href="random-forest.html#plotting-the-error-rate"><i class="fa fa-check"></i><b>4.4.1</b> Plotting the Error Rate</a></li>
<li class="chapter" data-level="4.4.2" data-path="random-forest.html"><a href="random-forest.html#tuning-mtry"><i class="fa fa-check"></i><b>4.4.2</b> Tuning mTry</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="random-forest.html"><a href="random-forest.html#recreate-our-random-forest-model"><i class="fa fa-check"></i><b>4.5</b> Recreate our Random Forest Model</a></li>
<li class="chapter" data-level="4.6" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---training-data"><i class="fa fa-check"></i><b>4.6</b> Rerun Predicition and Confusion Matrix - Training Data</a></li>
<li class="chapter" data-level="4.7" data-path="random-forest.html"><a href="random-forest.html#rerun-predicition-and-confusion-matrix---test-data"><i class="fa fa-check"></i><b>4.7</b> Rerun Predicition and Confusion Matrix - Test Data</a></li>
<li class="chapter" data-level="4.8" data-path="random-forest.html"><a href="random-forest.html#variable-importance"><i class="fa fa-check"></i><b>4.8</b> Variable Importance</a></li>
<li class="chapter" data-level="4.9" data-path="random-forest.html"><a href="random-forest.html#accuracy"><i class="fa fa-check"></i><b>4.9</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>5</b> K-Nearest Neighbor</a>
<ul>
<li class="chapter" data-level="5.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#data-partitioning-1"><i class="fa fa-check"></i><b>5.1</b> Data Partitioning</a></li>
<li class="chapter" data-level="5.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#determine-the-k-value"><i class="fa fa-check"></i><b>5.2</b> Determine the k-value</a></li>
<li class="chapter" data-level="5.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#knn-prediction"><i class="fa fa-check"></i><b>5.3</b> KNN Prediction</a></li>
<li class="chapter" data-level="5.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#accuracy-1"><i class="fa fa-check"></i><b>5.4</b> Accuracy</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lasso-regression.html"><a href="lasso-regression.html"><i class="fa fa-check"></i><b>6</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="lasso-regression.html"><a href="lasso-regression.html#linear-regression"><i class="fa fa-check"></i><b>6.1</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="lasso-regression.html"><a href="lasso-regression.html#what-is-it"><i class="fa fa-check"></i><b>6.1.1</b> What is it?</a></li>
<li class="chapter" data-level="6.1.2" data-path="lasso-regression.html"><a href="lasso-regression.html#assumptions"><i class="fa fa-check"></i><b>6.1.2</b> Assumptions</a></li>
<li class="chapter" data-level="6.1.3" data-path="lasso-regression.html"><a href="lasso-regression.html#single-variable"><i class="fa fa-check"></i><b>6.1.3</b> Single Variable</a></li>
<li class="chapter" data-level="6.1.4" data-path="lasso-regression.html"><a href="lasso-regression.html#multiple-variables"><i class="fa fa-check"></i><b>6.1.4</b> Multiple Variables</a></li>
<li class="chapter" data-level="6.1.5" data-path="lasso-regression.html"><a href="lasso-regression.html#less-variables"><i class="fa fa-check"></i><b>6.1.5</b> Less Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="lasso-regression.html"><a href="lasso-regression.html#ridge-regression"><i class="fa fa-check"></i><b>6.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="6.3" data-path="lasso-regression.html"><a href="lasso-regression.html#lasso-regression-1"><i class="fa fa-check"></i><b>6.3</b> Lasso Regression</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="lasso-regression.html"><a href="lasso-regression.html#features-of-the-glmnet-package"><i class="fa fa-check"></i><b>6.3.1</b> Features of the ‘glmnet’ Package</a></li>
<li class="chapter" data-level="6.3.2" data-path="lasso-regression.html"><a href="lasso-regression.html#elastic-net-regression"><i class="fa fa-check"></i><b>6.3.2</b> Elastic Net Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>7</b> Results</a></li>
<li class="chapter" data-level="8" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>8</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">COMP 4441 Final Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="k-nearest-neighbor" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> K-Nearest Neighbor</h1>
<p>K-Nearest Neighbor is a supervised machine learning algorithm that can be used for both classification and regression problems. It is able to classify a new data point by comparing its variables to those variables of its “nearest neighbors.” The Euclidean distance formula is used to determine which of the data points are closest to the new point. Similarly to Random Forest, KNN uses the consensus of those neighbors to predict the outcome variable for the new data point.</p>
<div id="data-partitioning-1" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Data Partitioning</h2>
<p>Our data has already been randomly partitioned into training and test data sets, however, the KNN algorithm we are utilizing within the caret library requires that we make our quality variables a “factor” data type.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="k-nearest-neighbor.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">444</span>)</span>
<span id="cb54-2"><a href="k-nearest-neighbor.html#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="k-nearest-neighbor.html#cb54-3" aria-hidden="true" tabindex="-1"></a>knn.train <span class="ot">&lt;-</span> train</span>
<span id="cb54-4"><a href="k-nearest-neighbor.html#cb54-4" aria-hidden="true" tabindex="-1"></a>knn.train<span class="sc">$</span>quality <span class="ot">&lt;-</span><span class="fu">as.factor</span>(knn.train<span class="sc">$</span>quality)</span>
<span id="cb54-5"><a href="k-nearest-neighbor.html#cb54-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-6"><a href="k-nearest-neighbor.html#cb54-6" aria-hidden="true" tabindex="-1"></a>knn.test <span class="ot">&lt;-</span> test</span>
<span id="cb54-7"><a href="k-nearest-neighbor.html#cb54-7" aria-hidden="true" tabindex="-1"></a>knn.test<span class="sc">$</span>quality <span class="ot">&lt;-</span><span class="fu">as.factor</span>(knn.test<span class="sc">$</span>quality)</span>
<span id="cb54-8"><a href="k-nearest-neighbor.html#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="k-nearest-neighbor.html#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(knn.test)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    1933 obs. of  12 variables:
##  $ fixed.acidity       : num  0.331 0.612 0.298 0.289 0.24 ...
##  $ volatile.acidity    : num  0.533 0.133 0.413 0.38 0.333 ...
##  $ citric.acid         : num  0 0.3373 0 0 0.0482 ...
##  $ residual.sugar      : num  0.0307 0.0199 0.0199 0.0092 0.0184 ...
##  $ chlorides           : num  0.148 0.11 0.111 0.093 0.146 ...
##  $ free.sulfur.dioxide : num  0.0833 0.0556 0.0347 0.0486 0.0486 ...
##  $ total.sulfur.dioxide: num  0.1406 0.1244 0.0645 0.0346 0.1359 ...
##  $ density             : num  0.187 0.21 0.206 0.144 0.169 ...
##  $ pH                  : num  0.372 0.341 0.612 0.519 0.434 ...
##  $ sulphates           : num  0.258 0.202 0.191 0.14 0.18 ...
##  $ alcohol             : num  0.261 0.261 0.203 0.29 0.174 ...
##  $ quality             : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 3 4 3 5 3 3 4 4 3 3 ...</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="k-nearest-neighbor.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(knn.train)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    4564 obs. of  12 variables:
##  $ fixed.acidity       : num  0.298 0.331 0.298 0.339 0.331 ...
##  $ volatile.acidity    : num  0.413 0.453 0.387 0.347 0.333 ...
##  $ citric.acid         : num  0 0.0241 0 0.0361 0.012 ...
##  $ residual.sugar      : num  0.0199 0.0261 0.0184 0.0153 0.0215 ...
##  $ chlorides           : num  0.1113 0.1379 0.1096 0.0997 0.1063 ...
##  $ free.sulfur.dioxide : num  0.0347 0.0486 0.0417 0.0486 0.0278 ...
##  $ total.sulfur.dioxide: num  0.0645 0.1106 0.0783 0.1221 0.0276 ...
##  $ density             : num  0.206 0.191 0.206 0.179 0.187 ...
##  $ pH                  : num  0.612 0.419 0.612 0.45 0.496 ...
##  $ sulphates           : num  0.191 0.242 0.191 0.135 0.197 ...
##  $ alcohol             : num  0.203 0.261 0.203 0.203 0.217 ...
##  $ quality             : Factor w/ 7 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 3 3 3 3 5 3 3 3 3 3 ...</code></pre>
<p>Because our data was randomly partitioned you can see there are 7 levels within quality factor in the train data, while there are only 6 levels within the quality factor in the test data. This will have to be managed later using the “droplevels” function, to find the accuracy using the confusionmatrix.</p>
</div>
<div id="determine-the-k-value" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Determine the k-value</h2>
<p>The k-value in the KNN algorithm determines how many of the nearest neighbors we will use to calculate our predicted quality. There are many different methods for computing the value of K, however, caret provides a built in library function “train” to help determine what the k-value we should utilize is.</p>
<p>“train” utilizes k-fold cross validation to determine the accuracy of each k-value value. For our model, we used the repeated cross-validation method which indicates using cross-validation and repeating it a number of times to ensure accuracy. For our parameters, we chose to repeat 5 times and left the default number of folds to 10, as that has been previously found to result in a low-bias model.</p>
<p>Within the train function, we define the method for training our model to be “knn” for k-nearest neighbor and our tune length to be 40. The tuneLength parameter tells the algorithm to try 40 different values of k.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="k-nearest-neighbor.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">400</span>)</span>
<span id="cb58-2"><a href="k-nearest-neighbor.html#cb58-2" aria-hidden="true" tabindex="-1"></a>tc <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;repeatedcv&quot;</span>,<span class="at">repeats =</span> <span class="dv">5</span>) <span class="co">#,classProbs=TRUE,summaryFunction = twoClassSummary)</span></span>
<span id="cb58-3"><a href="k-nearest-neighbor.html#cb58-3" aria-hidden="true" tabindex="-1"></a>k.value <span class="ot">&lt;-</span> <span class="fu">train</span>(quality <span class="sc">~</span> ., <span class="at">data =</span> knn.train, <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, <span class="at">trControl =</span> tc, <span class="at">tuneLength=</span><span class="dv">40</span>)</span>
<span id="cb58-4"><a href="k-nearest-neighbor.html#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="k-nearest-neighbor.html#cb58-5" aria-hidden="true" tabindex="-1"></a>k.value</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 4564 samples
##   11 predictor
##    7 classes: &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 5 times) 
## Summary of sample sizes: 4108, 4108, 4106, 4108, 4108, 4109, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    5  0.5321658  0.2858505
##    7  0.5389564  0.2902098
##    9  0.5389154  0.2868803
##   11  0.5335706  0.2749516
##   13  0.5314191  0.2693456
##   15  0.5371607  0.2765031
##   17  0.5348392  0.2710070
##   19  0.5356741  0.2702315
##   21  0.5383901  0.2736512
##   23  0.5388281  0.2735700
##   25  0.5416298  0.2764623
##   27  0.5418483  0.2759878
##   29  0.5397452  0.2716491
##   31  0.5434266  0.2766398
##   33  0.5410587  0.2723851
##   35  0.5418060  0.2724562
##   37  0.5423318  0.2729050
##   39  0.5420259  0.2713667
##   41  0.5432096  0.2732347
##   43  0.5431208  0.2726629
##   45  0.5408835  0.2686819
##   47  0.5414967  0.2691622
##   49  0.5410156  0.2676621
##   51  0.5408815  0.2668637
##   53  0.5395240  0.2638237
##   55  0.5391279  0.2630925
##   57  0.5389955  0.2621340
##   59  0.5379898  0.2603583
##   61  0.5393910  0.2621689
##   63  0.5371996  0.2589008
##   65  0.5373285  0.2588102
##   67  0.5378552  0.2590151
##   69  0.5373315  0.2577817
##   71  0.5372894  0.2572961
##   73  0.5364118  0.2556921
##   75  0.5384289  0.2584713
##   77  0.5382081  0.2577366
##   79  0.5377703  0.2569147
##   81  0.5377717  0.2563957
##   83  0.5358855  0.2530376
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 31.</code></pre>
<p>The plot below shows the accuracy of the repeated cross-validation models to the k-values from train. We can see that the highest level of accuracy was hit at k=37 and then appears to decrease in accuracy as k increases.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="k-nearest-neighbor.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k.value)</span></code></pre></div>
<p><img src="Final-Project---Bright-Santoro_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
</div>
<div id="knn-prediction" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> KNN Prediction</h2>
<p>Now that we have our k-value and knn model trained, we can use it to predict our test values. In this portion of code, we will also account for the missing level from the quality factor that we found earlier, so that we can compute our confusion matrix.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="k-nearest-neighbor.html#cb61-1" aria-hidden="true" tabindex="-1"></a>knnPredict <span class="ot">&lt;-</span> <span class="fu">predict</span>(k.value,<span class="at">newdata =</span> knn.test )</span>
<span id="cb61-2"><a href="k-nearest-neighbor.html#cb61-2" aria-hidden="true" tabindex="-1"></a>knnPredict<span class="fl">.2</span><span class="ot">&lt;-</span><span class="fu">droplevels</span>(knnPredict)</span>
<span id="cb61-3"><a href="k-nearest-neighbor.html#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="k-nearest-neighbor.html#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Get the confusion matrix to see accuracy value and other parameter values</span></span>
<span id="cb61-5"><a href="k-nearest-neighbor.html#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(knnPredict<span class="fl">.2</span>, knn.test<span class="sc">$</span>quality )</span></code></pre></div>
<pre><code>## Warning in levels(reference) != levels(data): longer object length is not a multiple of shorter object length</code></pre>
<pre><code>## Warning in confusionMatrix.default(knnPredict.2, knn.test$quality): Levels are not in the same order for reference and data. Refactoring data to match.</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   3   4   5   6   7   8
##          3   0   0   0   0   0   0
##          4   0   0   0   0   0   0
##          5   5  40 380 197  10   0
##          6   5  23 226 587 188  27
##          7   1   2  14  76 121  30
##          8   0   0   0   1   0   0
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5629          
##                  95% CI : (0.5404, 0.5851)
##     No Information Rate : 0.4454          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.3072          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: 3 Class: 4 Class: 5 Class: 6 Class: 7  Class: 8
## Sensitivity          0.000000  0.00000   0.6129   0.6818   0.3793 0.0000000
## Specificity          1.000000  1.00000   0.8081   0.5625   0.9238 0.9994670
## Pos Pred Value            NaN      NaN   0.6013   0.5559   0.4959 0.0000000
## Neg Pred Value       0.994309  0.96637   0.8155   0.6876   0.8828 0.9704969
## Prevalence           0.005691  0.03363   0.3207   0.4454   0.1650 0.0294878
## Detection Rate       0.000000  0.00000   0.1966   0.3037   0.0626 0.0000000
## Detection Prevalence 0.000000  0.00000   0.3270   0.5463   0.1262 0.0005173
## Balanced Accuracy    0.500000  0.50000   0.7105   0.6221   0.6516 0.4997335</code></pre>
<p>Our model was found to be about 56.75% accurate in predicting quality measures for our wine samples.</p>
</div>
<div id="accuracy-1" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Accuracy</h2>
<p>In the code below we are adding the percentage accuracy to the accuracy dataframe for later model comparison.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="k-nearest-neighbor.html#cb65-1" aria-hidden="true" tabindex="-1"></a>accuracy[<span class="dv">1</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(knnPredict<span class="fl">.2</span>, knn.test<span class="sc">$</span>quality )[[<span class="st">&quot;overall&quot;</span>]][[<span class="st">&quot;Accuracy&quot;</span>]]</span></code></pre></div>
<pre><code>## Warning in levels(reference) != levels(data): longer object length is not a multiple of shorter object length</code></pre>
<pre><code>## Warning in confusionMatrix.default(knnPredict.2, knn.test$quality): Levels are not in the same order for reference and data. Refactoring data to match.</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-forest.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lasso-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-KMeans_Testing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Final Project - Bright Santoro.pdf", "Final Project - Bright Santoro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
